# Cap√≠tulo 0: Una Nueva Forma de Estudiar el Comportamiento Adaptable

## El Problema con la Ense√±anza Tradicional

Imagina a un estudiante que acaba de terminar un curso introductorio de "Psicolog√≠a del Aprendizaje". Ha dedicado un semestre a estudiar condicionamiento cl√°sico (Pavlov y sus perros), condicionamiento operante (Skinner y sus palomas), programas de refuerzo (raz√≥n fija, intervalo variable), y quiz√°s, si tuvo suerte, un cap√≠tulo final sobre "temas avanzados" donde aparece brevemente la igualaci√≥n de Herrnstein. Al final del curso, ¬øqu√© tiene en su cabeza? Un cat√°logo de fen√≥menos: bloqueo, ensombrecimiento, moldeamiento, extinci√≥n, recuperaci√≥n espont√°nea, efecto de contraste. Una lista de nombres: Pavlov, Thorndike, Watson, Skinner, Tolman. Una colecci√≥n de protocolos experimentales: cajas de condicionamiento, laberintos en T, programas de refuerzo.

Lo que probablemente *no* tiene es una visi√≥n coherente de los principios que unifican estos fen√≥menos, ni una comprensi√≥n de por qu√© este campo sigue siendo relevante en el siglo XXI. Los hallazgos aparecen desconectados entre s√≠ y, peor a√∫n, desconectados de desarrollos contempor√°neos en neurociencias, inteligencia artificial, econom√≠a conductual y teor√≠a de la decisi√≥n.

La estrategia pedag√≥gica tradicional para ense√±ar aprendizaje y comportamiento adaptable, reflejada en la organizaci√≥n t√≠pica de los libros de texto, presenta casi exclusivamente las principales regularidades emp√≠ricas derivadas de m√°s de 100 a√±os de investigaci√≥n, organizadas alrededor de protocolos experimentales espec√≠ficos (condicionamiento cl√°sico, instrumental, entre otros). Si bien este enfoque tiene valor hist√≥rico y permite apreciar la riqueza emp√≠rica del campo, puede dejar frecuentemente al estudiante con la impresi√≥n de que este es un √°rea de conocimiento est√°tica, fragmentada y predominantemente de inter√©s hist√≥rico, llena de hallazgos aislados y con escasa coherencia conceptual.

Este curso adopta una estrategia diferente.

## La Promesa de Este Curso

### Un Problema Adaptativo Fundamental

En el centro de este curso est√° un problema biol√≥gico fundamental que todos los organismos deben resolver: **c√≥mo distribuir su comportamiento en el tiempo y en el espacio para maximizar la obtenci√≥n de recursos necesarios para sobrevivir y reproducirse**.

Un rat√≥n buscando alimento, un estudiante decidiendo cu√°nto tiempo dedicar a cada materia, un algoritmo de ajedrez evaluando jugadas, una bacteria movi√©ndose hacia nutrientes‚Äîtodos enfrentan variantes del mismo desaf√≠o. Deben aprender qu√© aspectos de su entorno predicen recompensas y castigos, y deben usar ese conocimiento para elegir cursos de acci√≥n que maximicen su √©xito.

### Dos Componentes Esenciales

El estudio del comportamiento adaptable busca los principios que permiten resolver este problema. Podemos descomponerlo en dos componentes fundamentales:

**1. El Problema del Conocimiento**: ¬øC√≥mo detectar y aprender las propiedades estad√≠sticas de la distribuci√≥n de recursos relevantes desde el punto de vista biol√≥gico y psicol√≥gico? Es decir, ¬øc√≥mo aprender a predecir aquello fundamental para la supervivencia y reproducci√≥n? Este es el problema de la **asignaci√≥n de cr√©dito**: cuando un recurso aparece (o un peligro se presenta), ¬øa cu√°l de los m√∫ltiples eventos, se√±ales o acciones previas debe asignarse la responsabilidad? ¬øQu√© predice qu√©?

**2. El Problema de la Acci√≥n**: ¬øC√≥mo usar eficientemente ese conocimiento para distribuir √≥ptimamente el comportamiento en el tiempo y en el espacio? Dado que sabemos algo sobre d√≥nde y cu√°ndo aparecen los recursos, ¬øc√≥mo decidimos qu√© hacer? Este es el problema de la **elecci√≥n** bajo restricciones: el tiempo es finito, los comportamientos compiten entre s√≠, y las decisiones tienen costos de oportunidad.

Estas dos preguntas‚Äî*¬øqu√© predice qu√©?* y *¬øqu√© hago ahora?*‚Äîorganizan todo el curso.

### Dos Or√≠genes de Soluciones

Las soluciones a estos problemas adaptativos tienen dos or√≠genes temporales diferentes:

**1. Soluciones Filogen√©ticas (Selecci√≥n Natural)**: En entornos relativamente constantes a lo largo de generaciones, la selecci√≥n natural puede codificar directamente en el genoma las respuestas apropiadas. El resultado es lo que llamamos **comportamiento adaptado**: reflejos, instintos, sesgos perceptuales y atencionales que no requieren aprendizaje individual. Un ejemplo es la "impronta" en aves‚Äîlos polluelos siguen al primer objeto en movimiento que ven despu√©s de nacer, t√≠picamente su madre.

**2. Soluciones Ontogen√©ticas (Aprendizaje)**: En entornos variables, vol√°tiles e inciertos‚Äîla norma para la mayor√≠a de los organismos‚Äîla selecci√≥n natural no puede anticipar todas las contingencias. En estos casos, evoluciona algo diferente: mecanismos que permiten **comportamiento adaptable**, la capacidad de ajustar el comportamiento dentro de la vida del organismo en respuesta a la experiencia. A esto le llamamos **aprendizaje**.

La teor√≠a de la selecci√≥n natural de Darwin resolvi√≥ el enigma de c√≥mo los rasgos pueden parecer dise√±ados sin necesidad de un dise√±ador: variaci√≥n, selecci√≥n por consecuencias, y retenci√≥n de lo exitoso. Veremos que los mecanismos del aprendizaje operan seg√∫n el mismo principio abstracto‚Äîensayo, error y selecci√≥n‚Äîpero a una escala temporal ontogen√©tica en lugar de filogen√©tica.

### Mecanismos Reutilizables: Las "Tuercas y Tornillos"

A lo largo del curso identificaremos un conjunto peque√±o de mecanismos generales‚Äîverdaderas "tuercas y tornillos" en el caj√≥n de herramientas de la adaptaci√≥n‚Äîque aparecen una y otra vez en diferentes contextos:

- **Comparaci√≥n** (sucesiva vs. simult√°nea): Detectar diferencias entre estados del mundo
- **Reducci√≥n de error**: Ajustar predicciones cuando difieren de resultados observados
- **Exploraci√≥n vs. Explotaci√≥n**: El dilema entre muestrear nuevas opciones y aprovechar lo conocido
- **Sistemas de retroalimentaci√≥n**: Lazos cerrados donde la acci√≥n modifica las condiciones que la provocan
- **Descuento temporal**: Valorar m√°s las consecuencias cercanas que las lejanas
- **Optimizaci√≥n bajo restricciones**: Encontrar la mejor distribuci√≥n posible de comportamiento dadas las limitaciones del entorno

Estos mecanismos no son curiosidades te√≥ricas. Son implementables, operan en robots y algoritmos de inteligencia artificial, y pueden estudiarse tanto a nivel conductual como neural.

## De Asociacionismo a Optimizaci√≥n: Un Siglo de Transformaciones

Para apreciar la novedad del enfoque de este curso, es √∫til entender brevemente c√≥mo evolucion√≥ el estudio del comportamiento adaptable durante el √∫ltimo siglo.

### La Tradici√≥n Asociacionista

Desde Descartes en el siglo XVII hasta mediados del siglo XIX, el estudio del conocimiento estuvo dominado por el asociacionismo: la idea de que aprendemos mediante la asociaci√≥n de ideas que ocurren juntas en el tiempo. Los fil√≥sofos empiristas propusieron que el conocimiento se adquiere a trav√©s de la experiencia y consiste en asociaciones formadas principalmente por **contig√ºidad temporal**‚Äîsi dos eventos ocurren juntos repetidamente, se asocian.

Para los fisi√≥logos de esa √©poca, los elementos b√°sicos de la acci√≥n eran **est√≠mulos** y **respuestas** discretas organizadas en **reflejos**. Un est√≠mulo dispara (provoca) una respuesta seg√∫n un conjunto de leyes del reflejo. Este esquema mecanicista fue elegante pero limitado: no explicaba c√≥mo aparecen comportamientos nuevos, ni c√≥mo esos comportamientos parecen dise√±ados para lograr metas espec√≠ficas.

Ivan Pavlov desarroll√≥ el protocolo del **condicionamiento cl√°sico** que permiti√≥ estudiar experimentalmente el asociacionismo. Mostr√≥ que un est√≠mulo neutral (un tono) pod√≠a adquirir la capacidad de provocar una respuesta (salivaci√≥n) si se apareaba repetidamente con un est√≠mulo que ya la provocaba (comida). El principio clave segu√≠a siendo la contig√ºidad temporal.

### El Funcionalismo: James y Dewey

**William James** fue la figura que jug√≥ el papel m√°s importante en incorporar la teor√≠a evolutiva a la psicolog√≠a. Resalt√≥ la importancia de la acci√≥n y su comprensi√≥n en t√©rminos de la **funci√≥n** que juega en la supervivencia de un organismo. Al enfatizar la funci√≥n del comportamiento, James expl√≠citamente llam√≥ la atenci√≥n sobre la obtenci√≥n de metas como parte central del estudio de la psicolog√≠a. En sus palabras: "la persecuci√≥n de metas futuras y la elecci√≥n de los medios para obtenerlas, son la marca y el criterio de la presencia de mentalidad... todos usamos esta prueba para discriminar una ejecuci√≥n inteligente de una mec√°nica". James logr√≥, con la perspectiva funcionalista que propuso, que la psicolog√≠a tuviera la estructura de una ciencia emp√≠rica y experimental.

**John Dewey** extendi√≥ y consolid√≥ el funcionalismo de James, a√±adiendo una cr√≠tica fundamental al esquema asociacionista dominante. Rechaz√≥ que la asociaci√≥n entre un est√≠mulo y una respuesta‚Äîcomo entidades discretas separables que conforman "arcos reflejos"‚Äîfuese la unidad de an√°lisis adecuada para la psicolog√≠a. Argument√≥ que los organismos no son entidades pasivas, meros receptores de estimulaci√≥n. Por el contrario, detr√°s de cada est√≠mulo encontramos una acci√≥n que lo produce. De ah√≠ que la **relaci√≥n de interdependencia entre organismo y entorno** sea la unidad de an√°lisis fundamental para la psicolog√≠a. Esta idea, revolucionaria en su momento, anticipa lo que d√©cadas despu√©s se formalizar√≠a como sistemas de retroalimentaci√≥n: el comportamiento no solo responde al entorno, lo modifica, y esas modificaciones a su vez afectan el comportamiento subsecuente.

### Primera Transformaci√≥n: Selecci√≥n por Consecuencias

La publicaci√≥n de *El Origen de las Especies* de Darwin en 1859 cambi√≥ radicalmente la forma de pensar sobre la adaptaci√≥n. La teor√≠a de la selecci√≥n natural explicaba c√≥mo los rasgos pod√≠an parecer dise√±ados sin necesidad de intenci√≥n o previsi√≥n: mediante un proceso de **ensayo y error** a escala evolutiva. Los organismos con rasgos que resultan en mayor √©xito reproductivo dejan m√°s descendencia; esos rasgos se vuelven m√°s comunes en la poblaci√≥n.

Edward Thorndike, estudiante de James, reconoci√≥ que este mismo principio podr√≠a aplicarse al comportamiento individual. En sus experimentos con gatos escapando de cajas-problema, observ√≥ que los animales probaban m√∫ltiples respuestas y gradualmente reten√≠an aquellas que eran exitosas. Propuso la primera versi√≥n de la **Ley del Efecto** (1898):

> "De entre las m√∫ltiples respuestas que pueden ocurrir ante una situaci√≥n, aquella que vaya seguida de un estado de cosas satisfactorio ser√° la que se asocia con esa situaci√≥n."

Tres elementos fueron revolucionarios aqu√≠: (1) el √©nfasis en las **consecuencias** del comportamiento como motor del aprendizaje, no solo la contig√ºidad; (2) la idea de **valor**: no cualquier consecuencia modifica el comportamiento, solo aquellas "satisfactorias" para el organismo; (3) el mecanismo de **ensayo y error**, an√°logo a la selecci√≥n natural pero operando en tiempo real.

Sin embargo, Thorndike no escap√≥ completamente de la tradici√≥n asociacionista: segu√≠a asumiendo que lo que se aprende son conexiones est√≠mulo-respuesta (E-R).

### Segunda Transformaci√≥n: De Respuestas Provocadas a Comportamiento Continuo

B.F. Skinner (1938) liber√≥ el estudio del comportamiento de su anclaje en el reflejo. Postul√≥ que la mayor√≠a de las respuestas son **emitidas**, no provocadas por un est√≠mulo identificable. Estas respuestas ocurren a lo largo del tiempo, y la forma natural de medirlas es por su **tasa de ocurrencia** (n√∫mero de respuestas por unidad de tiempo).

Skinner reformul√≥ la ley del efecto: las respuestas seguidas por un reforzador incrementan su probabilidad futura de ocurrencia. Dise√±√≥ espacios experimentales (las famosas "cajas de Skinner") donde los animales pod√≠an responder libremente, permitiendo estudiar la distribuci√≥n del comportamiento en el tiempo. Introdujo los **programas de refuerzo**‚Äîreglas que especifican la relaci√≥n entre la distribuci√≥n de respuestas y la distribuci√≥n de reforzadores‚Äîque resultaron mucho m√°s ricos que el simple "cada respuesta se refuerza".

Skinner tambi√©n distingui√≥ dos tipos de est√≠mulos: aquellos que **provocan** respuestas reflejas, y los **est√≠mulos discriminativos** que no provocan sino que **disponen la ocasi√≥n** para que una respuesta sea reforzada. Estos est√≠mulos indican al organismo los contextos apropiados para diferentes acciones.

Con Skinner, el comportamiento se convirti√≥ en un continuo temporal que puede ser moldeado, no una colecci√≥n de reflejos discretos.

### Tercera Transformaci√≥n: De H√°bitos E-R a Representaciones y Optimizaci√≥n

Edward C. Tolman, contempor√°neo de Skinner, cuestion√≥ la idea de que el aprendizaje consiste √∫nicamente en fortalecer conexiones E-R. Sus experimentos con ratas en laberintos mostraron que los animales aprenden sobre la **estructura del entorno**, no solo qu√© respuestas fueron reforzadas.

En el famoso experimento de **aprendizaje latente**, ratas que exploraron un laberinto sin recibir refuerzo aprendieron m√°s r√°pido cuando posteriormente se les reforz√≥ por encontrar la salida, comparadas con ratas sin esa experiencia exploratoria. Tolman propuso que las ratas formaban **mapas cognitivos**‚Äîrepresentaciones espaciales del entorno‚Äîy no solo cadenas de respuestas.

Tolman tambi√©n fue el primero en enfatizar expl√≠citamente que el comportamiento es **propositivo**: orientado a metas, no meramente mec√°nico. Los organismos no solo aprenden qu√© respuestas producen reforzadores; aprenden qu√© consecuencias est√°n vinculadas con qu√© respuestas, y eligen en funci√≥n del valor de esas consecuencias.

### La Integraci√≥n Contempor√°nea (1960-Presente)

A partir de la d√©cada de 1960, el estudio del comportamiento adaptable experiment√≥ una transformaci√≥n profunda mediante la integraci√≥n con otras disciplinas.

**Richard Herrnstein**, estudiante de Skinner, extendi√≥ el estudio de la tasa de respuesta al estudio de la **elecci√≥n**. En programas concurrentes (donde dos o m√°s opciones est√°n simult√°neamente disponibles), descubri√≥ una regularidad emp√≠rica fundamental: la **ley de igualaci√≥n**, que establece que los organismos distribuyen sus respuestas entre opciones en proporci√≥n a los reforzadores obtenidos de cada una. Este hallazgo conect√≥ el comportamiento con modelos econ√≥micos de elecci√≥n.

**Howard Rachlin y John Staddon**, estudiantes de Herrnstein, desarrollaron **modelos de optimizaci√≥n en equilibrio** inspirados en la microeconom√≠a y la ecolog√≠a del comportamiento. Propusieron que:
- Los comportamientos compiten por tiempo finito
- Los programas de refuerzo imponen restricciones sobre las posibles distribuciones de comportamiento  
- En equilibrio, se observa la distribuci√≥n que **maximiza el valor obtenido** dadas las restricciones

Estos modelos transformaron la ley del efecto de un principio de fortalecimiento a un principio de **optimizaci√≥n bajo restricciones**.

Simult√°neamente, nuevos protocolos experimentales revelaron limitaciones del asociacionismo cl√°sico. El fen√≥meno de **bloqueo** (Kamin, 1969) mostr√≥ que la contig√ºidad no es suficiente para el aprendizaje: un est√≠mulo redundante no se aprende aunque est√© perfectamente correlacionado con el reforzador. **Rescorla y Wagner (1972)** propusieron que el motor del aprendizaje no es la contig√ºidad sino la **reducci√≥n del error de predicci√≥n**: aprendemos cuando el resultado difiere de lo esperado.

Esta idea del error de predicci√≥n conect√≥ la psicolog√≠a del aprendizaje con la **teor√≠a de control** en ingenier√≠a y, d√©cadas despu√©s, con el **aprendizaje por refuerzo** en inteligencia artificial. El algoritmo de **diferencias temporales** (Sutton, 1988) generaliz√≥ el modelo de Rescorla-Wagner a secuencias de acciones, resolviendo el problema de la **asignaci√≥n de cr√©dito temporal**: ¬øcu√°l de las m√∫ltiples acciones en una secuencia fue responsable del reforzador que apareci√≥ al final?

Hoy, los mismos principios formales‚Äîerror de predicci√≥n, optimizaci√≥n bajo restricciones, exploraci√≥n vs. explotaci√≥n‚Äîaparecen en:
- **Neurociencias**: El sistema dopamin√©rgico codifica errores de predicci√≥n de recompensa
- **Inteligencia Artificial**: Q-learning, Actor-Cr√≠tico, y otros algoritmos de aprendizaje por refuerzo
- **Econom√≠a Conductual**: Funciones de utilidad, descuento temporal, teor√≠a de la perspectiva
- **Rob√≥tica**: Navegaci√≥n, control motor adaptativo, toma de decisiones aut√≥nomas

El estudio del comportamiento adaptable ha madurado hacia una ciencia cuantitativa y predictiva con aplicaciones que trascienden ampliamente la psicolog√≠a tradicional.

## El Enfoque de Este Curso

### Una Perspectiva Ingenieril

Este curso adopta lo que podr√≠amos llamar una **perspectiva ingenieril**: tratamos el comportamiento como una **soluci√≥n a problemas adaptativos espec√≠ficos**. Para cada fen√≥meno, preguntaremos no solo "¬øqu√© hacen los organismos?" sino tambi√©n:

- **¬øQu√© problema adaptativo est√°n resolviendo?** (¬øPor qu√© esto es importante para sobrevivir y reproducirse?)
- **¬øQu√© deber√≠a hacer un agente ideal?** (¬øCu√°l es la soluci√≥n √≥ptima dado el problema y las restricciones?)
- **¬øC√≥mo lo logran?** (¬øQu√© algoritmos o mecanismos implementan esa soluci√≥n o se aproximan a ella?)

Esta perspectiva conecta naturalmente con la distinci√≥n de niveles de an√°lisis propuesta por David Marr (1982) y relacionada con las cuatro preguntas de Tinbergen (1963):

**Nivel Computacional (¬øPor Qu√©?)**: ¬øQu√© problema est√° resolviendo el sistema? ¬øCu√°l es la l√≥gica de la tarea? Ejemplos: maximizar la tasa de obtenci√≥n de energ√≠a, minimizar incertidumbre sobre la ocurrencia de recursos, encontrar el camino m√°s corto en un laberinto.

**Nivel Algor√≠tmico (¬øC√≥mo?)**: ¬øQu√© representaciones y procesos implementan la soluci√≥n? Ejemplos: comparaci√≥n sucesiva de estados ambientales, actualizaci√≥n de valores mediante error de predicci√≥n, elecci√≥n probabil√≠stica proporcional a valores estimados.

**Nivel de Implementaci√≥n (¬øCon Qu√©?)**: ¬øQu√© estructuras f√≠sicas (neurales, gen√©ticas) realizan el algoritmo? Ejemplos: neuronas dopamin√©rgicas, circuitos cortico-estriatales, expresi√≥n g√©nica inducida por experiencia.

Estos niveles no compiten entre s√≠‚Äîson **complementarios**. Una explicaci√≥n completa requiere los tres. En este curso nos enfocaremos principalmente en los niveles computacional y algor√≠tmico, aunque haremos referencias al nivel de implementaci√≥n cuando sea relevante.

### Modelos Formales como Lenguaje Natural

Los modelos matem√°ticos que emplearemos‚Äîecuaciones diferenciales, funciones de probabilidad, algoritmos de optimizaci√≥n‚Äîno son ornamentos t√©cnicos para impresionar. Son el **lenguaje natural** para expresar con precisi√≥n los principios del comportamiento adaptable.

Considera la **ley de igualaci√≥n** de Herrnstein: describe algo profundo con elegancia compacta. Los organismos distribuyen su comportamiento entre opciones en proporci√≥n exacta a los reforzadores obtenidos de cada una. Si una paloma obtiene el doble de reforzadores picando la tecla izquierda que la derecha, picar√° el doble de veces la tecla izquierda. No solo *describe* el patr√≥n emp√≠rico; sugiere un **mecanismo** (igualaci√≥n como proceso de equilibrio) y permite **predicciones cuantitativas** para nuevas condiciones: si cambio la proporci√≥n de reforzadores, puedo predecir c√≥mo cambiar√° la proporci√≥n de respuestas.

O considera el **algoritmo de diferencias temporales**: imagina que vas camino a cenar en un restaurante nuevo. Tu experiencia se divide en momentos: caminando tienes cierta expectativa, ves una entrada fea y tu expectativa baja, entras y la mesera es amable (tu expectativa mejora), la comida resulta incre√≠ble. El algoritmo captura algo fundamental: no esperas al final para aprender. En cada momento actualizas tu estimaci√≥n comparando lo que esperabas con algo mejor: lo que acabas de obtener *m√°s* tu nueva expectativa del futuro. La diferencia‚Äîlo que llamamos **error de predicci√≥n temporal**‚Äîes precisamente lo que las neuronas dopamin√©rgicas del cerebro de mam√≠feros codifican cuando un animal aprende.

Las matem√°ticas no ocultan los principios‚Äîlos revelan. Y los simuladores que acompa√±an estas notas est√°n dise√±ados para hacer estas ideas formales accesibles e intuitivas.

### Los Simuladores como Herramientas de Descubrimiento

Los modelos formales que revisaremos pueden parecer abstractos cuando se presentan solo como ecuaciones en papel. Los **simuladores interactivos** que acompa√±an estas notas est√°n dise√±ados para transformar s√≠mbolos abstractos en comportamiento observable.

Cada simulador te permite:
- **Manipular par√°metros** y observar efectos inmediatos sobre el comportamiento del sistema
- **Reproducir experimentos cl√°sicos** con diferentes condiciones para ver qu√© cambia y qu√© permanece constante
- **Desarrollar intuici√≥n** sobre el comportamiento de sistemas complejos antes de formalizar esa intuici√≥n matem√°ticamente
- **Descubrir por ti mismo** relaciones que el texto describe, convirtiendo la lectura pasiva en exploraci√≥n activa

Los simuladores no son "extras" opcionales o meras ilustraciones‚Äîson parte integral de la estrategia pedag√≥gica de este curso. Est√°n organizados por tema y disponibles en:

**üîó https://www.bouzaslab25.com/**

A lo largo de las notas encontrar√°s secciones claramente marcadas que te dirigen a simuladores espec√≠ficos, con sugerencias sobre qu√© explorar y qu√© preguntas hacerte. Usa estas herramientas. Experimenta. Rompe las cosas (en el simulador, no en la realidad). El aprendizaje m√°s profundo ocurre cuando descubres, no solo cuando lees.

## Mapa del Curso

El curso est√° organizado en bloques tem√°ticos que siguen la l√≥gica del problema adaptativo que planteamos al inicio:

### **Bloque 0: Fundamentos Conceptuales** (Cap√≠tulos 0-3)
Establecemos el marco te√≥rico general: niveles de explicaci√≥n, el problema de la adaptabilidad, y la teor√≠a de la selecci√≥n natural como primera soluci√≥n. 

### **Bloque I: Mecanismos Sin Integraci√≥n de Historia** (Cap√≠tulos 4-5)
Estudiamos dos mecanismos fundamentales que permiten adaptaci√≥n en tiempo real sin requerir integraci√≥n de experiencias pasadas: **ascenso de colina** (comparaci√≥n sucesiva) y **sistemas de retroalimentaci√≥n** (comparaci√≥n simult√°nea). Estos son los "nuts and bolts" m√°s b√°sicos.

### **Bloque II: Marcos para Decisi√≥n Bajo Incertidumbre** (Cap√≠tulos 6-7)
Antes de abordar modelos espec√≠ficos de aprendizaje, introducimos dos marcos conceptuales generales: **Teor√≠a de Detecci√≥n de Se√±ales** (separar sensibilidad de criterio de decisi√≥n) e **Inferencia Bayesiana** (actualizar creencias con evidencia). Estos marcos nos dar√°n el lenguaje para entender los modelos posteriores.

### **Bloque III: El Problema del Conocimiento - Asignaci√≥n de Cr√©dito** (Cap√≠tulos 8-12)
Abordamos el problema central: cuando un reforzador aparece, ¬øa qu√© se le asigna el cr√©dito? Revisamos modelos cl√°sicos (Rescorla-Wagner) y sus extensiones contempor√°neas, incluyendo modelos basados en teor√≠a de la informaci√≥n y filtros bayesianos.

### **Bloque IV: El Problema de la Acci√≥n - Elecci√≥n y Optimizaci√≥n** (Cap√≠tulos 13-17)
Dado que hemos aprendido qu√© predice qu√©, ¬øc√≥mo distribuimos nuestro comportamiento? Estudiamos la ley del efecto, programas de refuerzo, la ley de igualaci√≥n, y culminamos con modelos de optimizaci√≥n en equilibrio que integran econom√≠a conductual.

### **Bloque V: Aprendizaje Secuencial** (Segundo Semestre)
Extendemos el an√°lisis a secuencias de acciones donde el reforzador aparece al final (problema de asignaci√≥n de cr√©dito temporal). Introducimos algoritmos de aprendizaje por refuerzo: diferencias temporales, Q-learning, Actor-Cr√≠tico.

### **Bloque VI: Incertidumbre y Estados Ocultos** (Segundo Semestre)
Finalmente, relajamos el supuesto de que el agente siempre sabe en qu√© estado del mundo se encuentra. Estudiamos entornos vol√°tiles, POMDPs, y modelos bayesianos avanzados.

---

**Diagrama Conceptual del Curso:**

```
                    PROBLEMA ADAPTATIVO FUNDAMENTAL
                    ¬øC√≥mo distribuir comportamiento para
                         maximizar recursos?
                                 |
                    +------------+------------+
                    |                         |
              CONOCIMIENTO                 ACCI√ìN
            ¬øQu√© predice qu√©?          ¬øQu√© hago ahora?
                    |                         |
         +----------+----------+              |
         |                     |              |
   Mecanismos          Asignaci√≥n      Elecci√≥n y
   Sin Historia        de Cr√©dito     Optimizaci√≥n
   (Caps 4-5)          (Caps 8-12)    (Caps 13-17)
         |                     |              |
         +----------+----------+--------------|
                    |                         |
              Aprendizaje                Incertidumbre
              Secuencial                 y Estados
              (Caps 18-22)               Ocultos
              [Semestre II]              (Caps 23-26)
                                         [Semestre II]
```

## C√≥mo Usar Estas Notas

### Para el Estudiante

Estas notas est√°n dise√±adas para **lectura activa**, no pasiva. Algunas sugerencias:

1. **Lee con l√°piz y papel a la mano**. Cuando aparece una ecuaci√≥n, no la saltes‚Äîdesarr√≥llala. Verifica las derivaciones. Sustituye n√∫meros concretos y calcula resultados.

2. **Usa los simuladores inmediatamente**. Cuando un cap√≠tulo menciona un simulador, ve a explorarlo *antes* de seguir leyendo. Primero juega, luego formaliza.

3. **Haz las preguntas inc√≥modas**. Si un modelo predice X pero sabes que en la realidad ocurre Y, no asumas que te falta entender‚Äîquiz√°s el modelo tiene limitaciones reales. An√≥talas. Muchos avances cient√≠ficos vienen de notar esas discrepancias.

4. **Conecta con tus conocimientos previos**. Si has tomado cursos de estad√≠stica, teor√≠a de la probabilidad, o programaci√≥n, busca las conexiones. Estos temas no existen en silos.

5. **S√© paciente con las matem√°ticas**. Algunas ecuaciones parecer√°n opacas al inicio. Regresa a ellas despu√©s de explorar el simulador. La intuici√≥n precede a la formalizaci√≥n.

### Para el Instructor

Estas notas pueden usarse de m√∫ltiples formas:

- **Como texto principal** en un curso de dos semestres sobre aprendizaje y comportamiento adaptable
- **Como complemento** a un texto tradicional, a√±adiendo la perspectiva formal y de optimizaci√≥n que esos textos omiten
- **Como recurso para temas espec√≠ficos** (e.g., solo los cap√≠tulos sobre aprendizaje por refuerzo, o solo los de modelos de optimizaci√≥n)

Los simuladores permiten clases invertidas: los estudiantes exploran antes de clase, y el tiempo presencial se dedica a discusi√≥n, resoluci√≥n de problemas, y profundizaci√≥n conceptual.

## Un Argumento Final

Muchos colegas me han dicho que es imposible ense√±ar estos temas‚Äîaprendizaje por refuerzo, modelos bayesianos, teor√≠a de la informaci√≥n‚Äîa nivel introductorio. Que los estudiantes de licenciatura no tienen las herramientas matem√°ticas. Que es mejor mantener el enfoque tradicional, descriptivo, organizado por protocolos.

Discrepo respetuosamente.

Los estudiantes de hoy crecieron con algoritmos de recomendaci√≥n, navegaci√≥n GPS, y juegos con IA. Tienen una intuici√≥n operativa sobre aprendizaje de m√°quinas que generaciones previas no ten√≠an. Lo que les falta no es capacidad‚Äîes un puente entre esa intuici√≥n informal y los principios formales.

Los simuladores interactivos, ejemplos concretos, y la conexi√≥n expl√≠cita con aplicaciones contempor√°neas construyen ese puente. Las matem√°ticas no necesitan ser una barrera; pueden ser una revelaci√≥n.

M√°s importante, privar a los estudiantes de esta perspectiva integradora‚Äîmantenerlos en el mundo de fen√≥menos desconectados del siglo XX‚Äîes hacerles un flaco favor. El comportamiento adaptable no es un museo de curiosidades hist√≥ricas. Es un campo vivo con aplicaciones en rob√≥tica, neurociencias computacionales, econom√≠a conductual, dise√±o de interfaces, y pol√≠ticas p√∫blicas.

Estas notas son un experimento pedag√≥gico. No tienen el pulido de un libro de editorial, ni las restricciones de extensi√≥n o contenido que imponen los mercados acad√©micos. Son un recurso abierto, en evoluci√≥n, dise√±ado para estudiantes que no le temen a los formalismos matem√°ticos y que merecen algo mejor que listas de fen√≥menos inconexos.

Si funcionan para ti‚Äîcomo estudiante o instructor‚Äîcomp√°rtelas. Si encuentras errores, omisiones, o secciones poco claras, comun√≠camelo. Este es un proyecto colaborativo en el mejor esp√≠ritu de la ciencia abierta.

---

**Ahora, comencemos.**

En el siguiente cap√≠tulo abordaremos una pregunta fundamental: **¬øQu√© significa "explicar" un fen√≥meno conductual?** Veremos que diferentes preguntas requieren diferentes tipos de respuestas, y que la confusi√≥n entre niveles de explicaci√≥n ha generado debates est√©riles en la historia de nuestra disciplina. Entender los niveles de an√°lisis nos permitir√° apreciar por qu√© los modelos formales, los algoritmos, y las soluciones √≥ptimas no compiten entre s√≠‚Äîson respuestas complementarias a preguntas diferentes.

```{python}
#| label: fig-aprendizaje
#| fig-cap: "Curva te√≥rica de aprendizaje"
#| echo: false

import numpy as np
import matplotlib.pyplot as plt

x = np.linspace(0, 10, 100)
y = 1 / (1 + np.exp(-x + 5))  # Funci√≥n sigmoide

plt.figure(figsize=(8, 4))
plt.plot(x, y, color='green', linewidth=2)
plt.title("Progreso esperado")
plt.xlabel("Tiempo")
plt.ylabel("Conocimiento")
plt.grid(True, linestyle='--')
plt.show()
```