# Capítulo 9: Asignación de Crédito a Respuestas {#sec-asignacion-respuestas}
## De la Predicción al Control

## Objetivos del Capítulo

Al finalizar este capítulo, deberías ser capaz de explicar la diferencia fundamental entre aprender relaciones predictivas (estímulo → SBI) y relaciones causales (respuesta → SBI), y comprender por qué el problema de asignación de crédito para respuestas requiere dos mecanismos complementarios: generación de variabilidad conductual y selección de respuestas exitosas. Evaluarás críticamente la Ley del Efecto de Thorndike y reconocerás sus limitaciones, distinguiendo entre contigüidad temporal y contingencia estadística. Comprenderás que la contigüidad no es ni necesaria ni suficiente para el aprendizaje de respuestas, y que los organismos son sensibles a relaciones causales genuinas, no solo a proximidad temporal. Finalmente, entenderás el concepto de conducta inducida como sesgo inductivo que estructura el espacio de respuestas candidatas, y cómo los organismos perciben causalidad de manera sofisticada, modulando esta percepción basándose en costos y beneficios.

---

## Introducción: El Salto de la Predicción al Control

El acceso a sucesos biológicamente importantes es fundamental para la supervivencia y reproducción de los organismos. En el capítulo anterior vimos cómo aquellos organismos que pueden predecir confiablemente la ocurrencia de los SBI tienen una ventaja comparativa en términos de su éxito reproductivo. Aprender que un cielo encapotado predice una fuerte lluvia le permite a un individuo anticiparse y prepararse correctamente para ella. De igual forma, escuchar un rugido le permite a una presa prepararse para el caso de un posible ataque.

Sin embargo, hay algo crucial que falta en esta historia. El individuo no tiene control sobre lo nublado del cielo, ni sobre la presencia del depredador dado el rugido. Puede predecir cuándo lloverá, pero no puede alterar el que llueva; puede predecir que detrás del rugido esté un depredador, pero no puede modificar su presencia. La predicción permite anticipación, pero no confiere control.

Uno de los saltos importantes en la historia evolutiva fue la emergencia de mecanismos biológicos que, a través de la acción y la interacción con el entorno, permiten a los organismos *controlar* la ocurrencia de sucesos biológicamente importantes. Estos mecanismos se encuentran estrechamente asociados a un componente específico de la estructura causal de los entornos: las relaciones que describen cuáles acciones de un organismo son exitosas para obtener mayores opciones de acceso a SBI.

Ejemplos de estas relaciones que describen acciones exitosas abundan en nuestra experiencia cotidiana y en la de otras especies. Los contratos laborales de nuestra especie contienen las reglas que especifican las acciones a seguir para acceder a un monto de dinero, lo que equivale a mayores opciones de SBI. Existen reglas que especifican qué acciones llevar a cabo si se desea tomar un transporte público. Hay reglas que definen las acciones requeridas para iniciar una relación amorosa. Las reglas que especifican a una mascota qué acciones le otorgan una comida especial. Las reglas que especifican a cada especie las acciones que facilitan su acceso a alimentos, así como los actos que les permiten escapar y evitar a sus depredadores.

Desde la psicología, nos preguntamos cómo un organismo logra reconocer dichas estructuras causales: específicamente, cómo puede determinar qué acción específica, entre muchas posibilidades, es la responsable del resultado deseado (el SBI). En los libros de texto, al estudio de la respuesta a esta pregunta se le conoce como *condicionamiento instrumental* o *condicionamiento operante*. En estas notas abordaremos su estudio con base en el mismo grupo de principios con los que abordamos los resultados de los protocolos de condicionamiento clásico.

---

## Parte I: El Problema Computacional y sus Mecanismos

### Los Orígenes: Thorndike y la Ley del Efecto

Antes de describir cómo se aplican los principios de asignación de crédito a las respuestas, es conveniente revisar el estudio original del que surgió esta área de investigación, siguiendo el mismo proceder que seguimos para entender el condicionamiento clásico. Al inicio del siglo XX, Edward Thorndike condujo una serie de estudios con gatos que cambiarían fundamentalmente nuestra comprensión del aprendizaje. Él diseñó una variedad de cajas experimentales—llamadas "cajas problema"—de las que un gato encerrado podría escapar activando dispositivos como un cerrojo o una palanca. Fuera de la caja había comida visible, un incentivo poderoso para el gato hambriento.

El procedimiento era simple pero revelador: un gato hambriento era encerrado en la caja, podía ver la comida afuera, y debía descubrir cómo operar el mecanismo de escape. Al lograrlo y escapar, obtenía acceso a la comida. Luego era devuelto a la caja para un nuevo ensayo. La medida crucial del aprendizaje era el tiempo que le tomaba al gato para escapar de la caja en cada ensayo.

Las observaciones de Thorndike fueron fascinantes. Al inicio, los gatos intentaban un número grande de respuestas aparentemente sin dirección: arañar paredes, maullar, caminar en círculos, morder los barrotes. Eventualmente, por aparente accidente, operaban el dispositivo que abría la puerta y obtenían acceso a la comida. Pero lo verdaderamente notable ocurría en ensayos subsecuentes: el tiempo para escapar disminuía gradualmente a través de los ensayos. Las respuestas incorrectas se volvían menos frecuentes, y la respuesta correcta emergía cada vez más rápido. Después de varios ensayos, el gato ejecutaba de forma casi inmediata la respuesta que fue exitosa para escapar.

Thorndike caracterizó esta ejecución como una de *ensayo y error*: el gato intentaba diferentes respuestas (ensayos) y las descartaba si no lo llevaban a salir de la caja (error). Para explicar estos resultados, Thorndike propuso un principio que se conoce como la *Ley del Efecto*, la cual establece que: "En la presencia de un estímulo (situación, contexto) pueden ocurrir una multitud de respuestas. Aquella que vaya seguida de un estado de cosas satisfactorio tendrá que ser la que se asocia (conecta, selecciona) con el estímulo."

En terminología contemporánea, el "estímulo" es el contexto o situación discriminativa, el "estado de cosas satisfactorio" es el reforzador positivo o SBI apetitivo, y "asociar" o "conectar" se refiere al incremento en la probabilidad de la respuesta. El mecanismo implícito en la formulación de Thorndike es que la contigüidad temporal entre respuesta y reforzador fortalece la conexión estímulo-respuesta.

### Dos Observaciones, Dos Mecanismos Necesarios

Es posible identificar que el resultado de los experimentos de Thorndike está compuesto de dos observaciones que requieren explicación. La primera es el conjunto de respuestas variadas que lleva a cabo el gato antes de emitir la respuesta correcta. ¿De dónde vienen estas respuestas? ¿Por qué el gato no se queda inmóvil esperando? ¿Qué determina el repertorio de respuestas que el gato intenta? La segunda observación es que después de varios ensayos, el gato ejecuta de forma casi exclusiva e inmediata la respuesta que fue exitosa para escapar de la caja. ¿Cómo se selecciona la respuesta correcta entre todas las probadas? ¿Por qué desaparecen las respuestas incorrectas? ¿Qué marca a una respuesta como "la correcta"?

Para analizar estos dos aspectos que ilustra el comportamiento de ensayo y error, recordemos que en el capítulo anterior vimos que el encuentro inesperado con un suceso biológicamente importante echa a andar dos mecanismos complementarios: uno que controla el comportamiento apropiado para la interacción con y búsqueda adicional del SBI, y un segundo mecanismo que permite predecir y controlar su futura ocurrencia.

Recordemos también que los sesgos inductivos pueden dividirse en dos clases: aquellos que determinan qué elementos—en nuestro caso respuestas—conforman el espacio de candidatos a la asignación de crédito, y los sesgos que determinan cuál elemento dentro del espacio se debe considerar primero. Esta distinción tiene un paralelo profundo con los mecanismos de la evolución biológica.

En el caso del primer sesgo, el que delimita el espacio de respuestas candidato a la asignación de crédito, las respuestas inducidas por el SBI juegan un papel equivalente al de las mutaciones y la recombinación genética dentro del proceso de generación de variabilidad en la teoría de la evolución. Las respuestas del organismo y la variabilidad genética coinciden en que ambas generan el espacio de opciones seleccionables (candidatos) dentro de los procesos de selección de los que forman parte. En la teoría de evolución, un conjunto de genes creado por las mutaciones y la recombinación genética es sometido a un proceso de selección por los cambios en el entorno. En la teoría de los sesgos inductivos para respuestas, un conjunto de respuestas generadas por un organismo en su interacción con el entorno es sometido a un proceso de selección por los sesgos inductivos del organismo.

Por otra parte, el segundo sesgo referido, aquel que establece el orden de prioridad para evaluar las respuestas candidato, es equivalente a los procesos específicos de selección natural. De la misma forma en que en la selección natural se dan procesos bien definidos para descartar y conservar genes particulares de entre un amplio espacio de candidatos, existen procesos bien definidos a nivel de los sesgos inductivos del organismo que describen cómo este prioriza, descarta y conserva las respuestas de entre su espacio de candidatos.

La Ley del Efecto de Thorndike prioriza a la contigüidad como el factor que determina tanto el espacio de candidatos como el orden que establece cuáles elementos evaluar primero. Crucialmente, la ley no toma en cuenta el origen de las respuestas que anteceden al "estado de cosas satisfactorio". Este último término al poco tiempo se convertiría en el concepto que hoy conocemos como "refuerzos" y que en estas notas llamamos también SBI. En lo que resta del capítulo, revisaremos la historia y la evidencia acerca del papel de la contigüidad en la asignación de crédito para una respuesta.

---

## Parte II: ¿Es la Contigüidad Suficiente? El Experimento de Superstición

En 1948, B.F. Skinner publicó los resultados de un pequeño experimento diseñado para demostrar la suficiencia de la contigüidad para el aprendizaje de respuestas. A las palomas hambrientas se les presentó comida cada 15 segundos, independientemente de su comportamiento. Crucial para el diseño experimental: la comida se presentaba automáticamente por un mecanismo temporal, sin ninguna relación causal con lo que el animal hacía.

Se observó que, a pesar de que la comida era completamente independiente del comportamiento, muchas palomas desarrollaron comportamientos estereotipados, como girar en círculos o picotear ciertas áreas. Lo notable era que los comportamientos diferían de paloma a paloma: una giraba en sentido antihorario, otra movía la cabeza como péndulo, otra picoteaba el piso en un lugar específico, otra daba cuartos de vuelta. Cada ave desarrollaba su propio ritual idiosincrásico.

Skinner explicó estos resultados señalando que para cada ave, una respuesta ocurría de forma accidental inmediatamente antes del refuerzo y esa contigüidad era responsable del fortalecimiento de dicha respuesta. El argumento era que la respuesta que por azar precedía inmediatamente la entrega de comida se fortalecía, haciéndola más probable en el futuro, lo que incrementaba la probabilidad de que nuevamente precediera la siguiente entrega de comida, creando un ciclo de auto-reforzamiento. A partir de este tipo de observaciones, Skinner concluyó que: "Decir que un reforzador es contingente sobre una respuesta no significa otra cosa que decir que se presenta después de la respuesta". Para Skinner, presumiblemente, el condicionamiento ocurre únicamente debido a la relación temporal expresada en términos de la proximidad entre la respuesta y el reforzador.

La interpretación de Skinner tuvo una influencia enorme en la psicología del aprendizaje durante décadas. Parecía demostrar que la contigüidad era no solo necesaria sino también suficiente para el aprendizaje de respuestas. Pero esta historia simple fue rápidamente cuestionada.

### La Réplica de Staddon y Simmelhag: Conducta Inducida

En 1971, Staddon y Simmelhag publicaron una réplica meticulosa del estudio de Skinner que cambiaría fundamentalmente nuestra comprensión del fenómeno. Al igual que Skinner, a un grupo de palomas se le dio acceso a comida cada 15 segundos, independientemente de su comportamiento. Pero a diferencia de Skinner, estos investigadores observaron cuidadosamente el comportamiento de las palomas a lo largo de todo el intervalo de 15 segundos, no solo justo antes de la entrega de comida.

Los resultados fueron reveladores. No encontraron evidencia convincente de que se aprendiera la respuesta individual que accidentalmente antecedía el acceso a la comida de la manera que Skinner había propuesto. No obstante, observaron algo sistemático y fascinante: para todas las palomas, el comportamiento desplegado se podía agrupar en dos clases distintas con propiedades temporales características.

Primero identificaron respuestas que ocurrían consistentemente al final del intervalo, a las que llamaron "respuestas terminales", las cuales incluían, entre otras, el orientarse hacia la pared del comedero, picotear cerca del comedero, y movimientos de la cabeza característicos del consumo. Segundo, identificaron una clase de respuestas que agrupaba comportamientos que ocurrían predominantemente a la mitad del intervalo, a las que llamaron "respuestas interinas", entre las cuales se observó la conducta de picar el piso, caminar en círculos, y movimientos exploratorios generales.

Crucialmente, este patrón era consistente entre palomas. No era que cada paloma desarrollara un comportamiento idiosincrásico completamente arbitrario como Skinner había sugerido. Más bien, todas las palomas mostraban la misma estructura temporal: conductas interinas en la mitad del intervalo, conductas terminales al final. Las conductas específicas podían variar ligeramente entre individuos, pero pertenecían consistentemente a estas dos categorías funcionales.

El estudio fue replicado con ratas y se observó el mismo patrón de agrupación de respuestas en dos clases con propiedades temporales distintivas. En ratas, las respuestas terminales incluían comportamientos orientados hacia el dispensador de comida, mientras que las respuestas interinas incluían comportamientos como beber agua (polidipsia inducida), correr en ruedas de actividad, y comportamientos exploratorios.

### Implicaciones para la Asignación de Crédito

De los resultados del experimento de Staddon y Simmelhag pueden extraerse dos conclusiones fundamentales. Primero, en relación directa al tema de este capítulo, podemos concluir que en experimentos donde no existe una relación netamente causal entre respuesta y SBI, el reforzador no selecciona simplemente a la respuesta que accidentalmente le antecede, contradiciendo la idea de que la contigüidad es una condición suficiente para el aprendizaje de respuestas.

La segunda conclusión, igualmente importante, es positiva: la mera presentación de un SBI induce un conjunto tipificado y estructurado de respuestas, y la periodicidad de la presentación del SBI organiza el comportamiento de los organismos alrededor del tiempo. Este fenómeno, que ahora llamamos *conducta inducida*, representa un sesgo inductivo fundamental del primer tipo—determina qué respuestas conforman el espacio de candidatos para la asignación de crédito.

Esta perspectiva conecta directamente con la teoría de sistemas de comportamiento de Hogan y Timberlake que discutimos en el capítulo anterior. La presentación de comida no genera respuestas arbitrarias; activa el sistema de comportamiento de alimentación con su estructura temporal característica. Este sistema incluye una secuencia de modos: primero conductas de búsqueda general (interinas), luego conductas focalizadas de aproximación y consumación (terminales). El reforzamiento no crea respuestas de la nada, sino que selecciona y da forma a la variabilidad preexistente y estructurada que emerge de estos sistemas de comportamiento.

En otras palabras, cuando Thorndike observó que sus gatos intentaban múltiples respuestas antes de encontrar la correcta, estas respuestas no eran completamente aleatorias. Eran respuestas del sistema de escape/exploración, un sistema evolutivamente preparado para resolver problemas de confinamiento. El sistema provee la variabilidad, el reforzamiento provee la selección.

---

## Parte III: ¿Es la Contigüidad Necesaria? Aprendizaje con Demora

En el experimento de superstición de Skinner no había una relación de dependencia causal entre respuesta y refuerzo, y Skinner buscaba demostrar que la mera contigüidad era suficiente para el aprendizaje de respuestas. Ya vimos que esta demostración falló. Pero ahora debemos preguntarnos por el rol de la contigüidad desde otra perspectiva: ¿es la contigüidad una condición necesaria para el aprendizaje de respuestas?

La especificación precisa de "contigüidad" es crucial aquí. Para estudiar sistemáticamente el papel de la contigüidad, es necesario especificar la ventana temporal que define a dos eventos como contiguos. La estrategia teórica-experimental inicial en esta área fue considerar como contigüidad estricta una ventana de cero segundos y considerar el impacto de ventanas mayores como distintas instancias de efectos de la demora en el refuerzo.

Los primeros estudios que manipularon la demora entre respuesta y reforzador parecían sugerir que la contigüidad era efectivamente necesaria. Con demoras de solo unos pocos segundos, el aprendizaje de respuestas se deterioraba rápidamente. Este gradiente de demora para respuestas parecía análogo al gradiente de demora que Pavlov había encontrado para estímulos en condicionamiento clásico. Sin embargo, estos estudios tempranos tenían un problema metodológico serio: durante la demora entre la respuesta y el reforzador, el animal típicamente emitía otras respuestas. Cuando finalmente llegaba el reforzador, estaba contiguamente relacionado no con la respuesta original que había iniciado la demora, sino con alguna respuesta más reciente.

### Los Experimentos de Dickinson: Aprendizaje Genuino con Demora

A finales de los años 80 y principios de los 90, Anthony Dickinson y sus colaboradores diseñaron una serie de experimentos ingeniosos que resolvieron este problema metodológico. Estos experimentos demostraron de manera convincente que las ratas y las palomas pueden aprender respuestas aun con demoras sustanciales entre la respuesta y el reforzador.

El diseño crucial fue el siguiente: después de que el animal emitía la respuesta objetivo (típicamente presionar una palanca para ratas o picotear una tecla para palomas), la tecla o palanca se retiraba completamente del ambiente durante el período de demora. Esto eliminaba la posibilidad de emitir la respuesta objetivo durante la demora, previniendo así cualquier contigüidad accidental entre respuestas recientes y el reforzador. Cuando el reforzador finalmente se presentaba después de la demora, la única respuesta objetivo que había ocurrido era aquella respuesta inicial que había iniciado el intervalo de demora.

Los resultados fueron sorprendentes para quienes creían en la necesidad estricta de la contigüidad: las palomas y las ratas podían aprender la respuesta objetivo con demoras de hasta 32 segundos entre la respuesta y el reforzador. Es cierto que el aprendizaje era más lento y menos robusto que con demoras cortas—existía claramente un gradiente de demora. Pero el punto crucial es que el aprendizaje ocurría incluso con estas demoras sustanciales, demostrando que la contigüidad estricta no es una condición necesaria para el aprendizaje de respuestas.

### El Problema de la Contigüidad Accidental

Pero estos experimentos dejaban abierta una pregunta importante. Aunque la respuesta objetivo no podía ocurrir durante la demora, el animal necesariamente estaba haciendo algo durante esos segundos. ¿Podrían otras respuestas que el animal emitía durante el período de demora estar adquiriendo fuerza por contigüidad accidental con el reforzador? ¿Y podría esta contigüidad accidental explicar el aprendizaje observado de la respuesta objetivo?

Kenneth Lattal diseñó un experimento elegante para responder esta pregunta. Utilizó un procedimiento llamado DRO modificado (Differential Reinforcement of Other behavior). El diseño funcionaba así: cuando el animal emitía la respuesta objetivo (presionar una palanca), se iniciaba un temporizador de 10 segundos. Si el animal no emitía ninguna respuesta objetivo adicional durante esos 10 segundos completos, entonces se entregaba el reforzador. Pero si el animal emitía otra respuesta objetivo antes de que transcurrieran los 10 segundos, el temporizador se reiniciaba a cero.

Este procedimiento garantizaba una demora mínima de 10 segundos entre cualquier respuesta objetivo y el reforzador subsecuente. Era imposible que existiera contigüidad accidental entre la respuesta objetivo y el reforzador—de hecho, el procedimiento reforzaba explícitamente la ausencia de la respuesta durante el período de demora.

A pesar de estas condiciones que eliminaban completamente la posibilidad de contigüidad, las ratas y palomas aprendieron a emitir la respuesta objetivo. Más aún, la tasa de la respuesta objetivo incrementó sistemáticamente a lo largo del entrenamiento. Este resultado es imposible de reconciliar con una teoría basada puramente en contigüidad temporal. Si la contigüidad fuera necesaria, estas condiciones deberían haber prevenido completamente el aprendizaje, o incluso haberlo suprimido activamente dado que el procedimiento reforzaba explícitamente la ausencia de la respuesta.

### La Lógica Detrás del Aprendizaje con Demora

¿Cómo pueden los organismos aprender bajo estas condiciones? La respuesta requiere que reconozcamos que los organismos no están simplemente detectando contigüidad temporal inmediata. Están detectando una forma más abstracta de relación causal: la contingencia estadística o correlación entre la presencia de una respuesta y la tasa de obtención de reforzadores.

En el procedimiento de Lattal, aunque no hay contigüidad entre respuestas individuales y reforzadores individuales, existe una contingencia estadística clara: la presencia de la respuesta objetivo (emitirla y luego abstenerse) lleva a una tasa de reforzamiento mayor que la ausencia de la respuesta objetivo. Los organismos pueden detectar esta contingencia estadística incluso cuando las contigüidades temporales inmediatas están ausentes o son contradictorias.

Esta capacidad para integrar información sobre largos períodos de tiempo y detectar correlaciones estadísticas es precisamente lo que la perspectiva molar de William Baum enfatiza. Baum distingue entre dos escalas de análisis temporal del comportamiento. La perspectiva molecular examina eventos locales en el tiempo: esta respuesta específica, seguida por este reforzador específico. La perspectiva molar examina patrones agregados: la tasa de una actividad correlacionada con la tasa de reforzamiento a lo largo de períodos extendidos.

El aprendizaje con demora sugiere fuertemente que los organismos operan, al menos en parte, en una escala molar. No están simplemente formando asociaciones momento a momento basadas en contigüidad. Están estimando correlaciones entre clases de actividad y resultados a lo largo del tiempo. Esta capacidad les permite aprender relaciones causales genuinas incluso cuando las contigüidades temporales inmediatas son débiles o ausentes.

---

## Parte IV: Percepción de Causalidad y Detección de Señales

Los experimentos que hemos revisado demuestran que la contigüidad no es ni necesaria ni suficiente para el aprendizaje de respuestas. Pero esto nos lleva a una pregunta más profunda: ¿pueden los organismos realmente discriminar entre consecuencias que son dependientes de sus respuestas versus consecuencias que son independientes? Es decir, ¿pueden detectar causalidad genuina?

### El Experimento de Killeen: Discriminación de Causalidad

Peter Killeen diseñó un experimento brillante para responder esta pregunta. El diseño era conceptualmente similar a un experimento de detección de señales, pero aplicado a la percepción de causalidad. Las palomas fueron entrenadas en un procedimiento donde podían "producir" cambios en el ambiente (apagar una luz) picoteando una tecla. Crucialmente, Killeen manipuló dos variables independientes.

Primero, manipuló la verdadera contingencia causal. En algunos ensayos, el picoteo de la paloma efectivamente producía el apagado de la luz (ensayos con respuesta-consecuencia). En otros ensayos, la luz se apagaba por un mecanismo temporal independiente del comportamiento de la paloma (ensayos sin respuesta-consecuencia o "pseudo-respuestas"). La paloma no tenía forma de saber con certeza, en cualquier ensayo dado, si su picoteo había causado el cambio o si este había ocurrido independientemente.

Después de que la luz se apagaba, se presentaban dos teclas de elección a la paloma. Si picoteaba la tecla A, estaba reportando "Sí, mi respuesta causó ese cambio". Si picoteaba la tecla B, estaba reportando "No, mi respuesta no causó ese cambio". La paloma era entonces reforzada por juicios correctos. Si el cambio había sido efectivamente causado por su respuesta y la paloma picoteaba A (un "hit" o acierto), recibía un reforzador. Si el cambio había sido independiente y la paloma picoteaba B (un "rechazo correcto"), también recibía un reforzador. Pero los errores—falsas alarmas y fallos—no eran reforzados.

El segundo aspecto crucial del diseño era que Killeen manipuló la magnitud del reforzador para los hits. En algunas condiciones, los hits producían una pequeña cantidad de comida. En otras condiciones, los hits producían una cantidad grande de comida. Las falsas alarmas nunca eran reforzadas, independientemente de la condición.

Los resultados fueron reveladores en dos sentidos. Primero, las palomas podían discriminar entre consecuencias dependientes e independientes de su respuesta significativamente mejor que el azar. Cuando se graficaban sus datos en un espacio ROC (Receiver Operating Characteristic)—tasa de hits versus tasa de falsas alarmas—las curvas estaban consistentemente por encima de la diagonal que representa desempeño al azar. Esto demostraba que las palomas poseían genuina sensibilidad a la causalidad. Podían detectar, mejor que por conjetura aleatoria, cuándo sus acciones habían causado un evento versus cuándo el evento había ocurrido independientemente.

Segundo, y esto es crucial, la estrategia de respuesta de las palomas cambiaba sistemáticamente con la magnitud del reforzador para los hits. Cuando los hits producían grandes recompensas, las palomas incrementaban su tasa de reportar "Sí, yo lo causé"—lo que incrementaba tanto hits como falsas alarmas. Cuando los hits producían pequeñas recompensas, las palomas eran más conservadoras, reduciendo tanto hits como falsas alarmas.

Este patrón es exactamente lo que predice la teoría de detección de señales. Las palomas no estaban simplemente respondiendo basándose en su capacidad perceptual de detectar causalidad. Estaban ajustando su criterio de decisión basándose en los costos y beneficios de diferentes tipos de errores. Cuando los hits valían mucho, era adaptativo reportar causalidad más liberalmente, aceptando un incremento en falsas alarmas como costo inevitable. Cuando los hits valían poco, era adaptativo ser más conservador.

### El Rol del Tiempo en la Percepción de Causalidad

En el mismo experimento, Killeen también manipuló el intervalo de tiempo entre el picoteo de la paloma y el apagado de la luz en los ensayos de pseudo-respuesta. Encontró que las falsas alarmas disminuían sistemáticamente conforme ese intervalo aumentaba de 0.2 segundos a 1.0 segundo. Es decir, a mayor distancia temporal entre la respuesta y el evento accidental, existía una menor probabilidad de que la paloma le asignara poder causal a su respuesta para explicar la ocurrencia del evento.

Este resultado demuestra que, aunque la contigüidad estricta no es necesaria para el aprendizaje (como vimos en los experimentos de demora), la proximidad temporal sigue siendo un factor importante en los juicios de causalidad. Los organismos usan múltiples fuentes de información para inferir causalidad: la contingencia estadística a largo plazo, la contigüidad temporal, la magnitud del efecto, y los patrones de covariación. La integración de todas estas fuentes les permite hacer inferencias causales sofisticadas y adaptativas.

Ponderen ustedes mismos qué harían en esta situación. Imaginen que un hit—reportar correctamente que su acción causó un resultado—les produjera diez pesos, y una falsa alarma—reportar incorrectamente que su acción causó un resultado que fue en realidad accidental—les costara un peso. ¿Qué tan liberal serían al reportar causalidad? Ahora consideren qué harían si los hits les otorgaran mil pesos y las falsas alarmas siguieran costando un peso. Incrementen ahora la ganancia para los hits a diez mil pesos. Seguramente, conforme la ganancia para los hits fuese incrementando, su estrategia se iría acercando a responder con mayor frecuencia que ustedes produjeron el cambio, aunque la probabilidad real de que esta relación causal sea verdadera se mantiene inalterada.

Este es precisamente el patrón que Killeen observó en las palomas. No se comportan como detectores perfectos de causalidad que reportan objetivamente la realidad física. Se comportan como agentes racionales que ajustan sus inferencias causales basándose en la estructura de payoffs del ambiente. Esta flexibilidad adaptativa en los juicios de causalidad es una característica sofisticada del aprendizaje operante que va mucho más allá de la formación simple de asociaciones por contigüidad.

---

## Conceptos Clave y Síntesis

Este capítulo ha explorado cómo los organismos aprenden relaciones causales entre sus acciones y consecuencias importantes, un problema que representa un salto evolutivo fundamental desde la mera predicción hasta el control activo del ambiente. El problema computacional es análogo al de la asignación de crédito para estímulos que estudiamos en el capítulo anterior, pero con complejidades adicionales introducidas por el hecho de que el organismo mismo genera la variabilidad conductual sobre la cual opera la selección.

El análisis histórico comenzando con Thorndike reveló que el aprendizaje de respuestas requiere dos mecanismos complementarios. Primero, debe existir un mecanismo que genere variabilidad conductual—el repertorio de respuestas candidatas sobre las cuales puede operar la selección. Segundo, debe existir un mecanismo de selección que determine cuáles de estas respuestas candidatas reciben crédito por la producción de consecuencias valiosas. La Ley del Efecto de Thorndike propuso que la contigüidad temporal entre respuesta y reforzador era el principio que gobernaba ambos mecanismos, pero la evidencia empírica subsecuente demostró que esta formulación era inadecuada.

El experimento de superstición de Skinner parecía demostrar que la contigüidad era suficiente para el aprendizaje—que cualquier respuesta que accidentalmente precediera un reforzador sería fortalecida. Pero la réplica meticulosa de Staddon y Simmelhag reveló una historia más compleja. No era que respuestas arbitrarias fueran seleccionadas por contigüidad accidental. Más bien, la presentación del reforzador inducía un conjunto estructurado de respuestas organizadas temporalmente: conductas interinas en la mitad del intervalo entre reforzadores y conductas terminales justo antes de la entrega del reforzador. Este patrón de conducta inducida refleja la activación de sistemas de comportamiento evolutivamente preparados, no la formación arbitraria de asociaciones por contigüidad.

Esta observación conecta con un principio más general que emerge tanto del estudio de estímulos como de respuestas: los sesgos inductivos no son limitaciones arbitrarias sino soluciones evolutivas a problemas computacionales reales. En el caso de respuestas, el sistema de comportamiento activado por el SBI determina qué respuestas conforman el espacio de candidatos para la asignación de crédito. El reforzamiento no crea respuestas de la nada; selecciona y da forma a variabilidad preexistente y estructurada. Esta es la solución evolutiva al primer aspecto del problema computacional.

Los experimentos de aprendizaje con demora de Dickinson y Lattal demostraron que la contigüidad tampoco es necesaria para el aprendizaje de respuestas. Los organismos pueden aprender relaciones respuesta-reforzador con demoras de decenas de segundos, e incluso en procedimientos que explícitamente eliminan o invierten las contingencias temporales locales. Esta capacidad revela que los organismos no están simplemente registrando asociaciones momento a momento basadas en proximidad temporal. Están operando en una escala temporal más extendida, detectando correlaciones estadísticas entre clases de actividad y tasas de reforzamiento.

Aquí emerge la distinción crucial entre perspectivas moleculares y molares del aprendizaje, articulada por William Baum. La perspectiva molecular examina eventos locales: esta respuesta específica seguida por este reforzador específico. La perspectiva molar examina patrones agregados: cómo la asignación de tiempo a diferentes actividades se correlaciona con tasas de reforzamiento a lo largo de períodos extendidos. Los experimentos de demora sugieren que los organismos pueden operar en ambas escalas, pero que la escala molar es la que realmente captura las relaciones causales fundamentales que gobiernan la adaptación.

Finalmente, los experimentos de Killeen sobre percepción de causalidad revelaron la sofisticación del sistema. Los organismos no solo pueden aprender bajo condiciones de demora; pueden activamente discriminar entre consecuencias que son dependientes versus independientes de sus acciones. Poseen sensibilidad genuina a la causalidad. Pero más allá de esto, sus juicios de causalidad no son rigidamente determinados por la estructura física del ambiente. Son flexibles y se ajustan adaptativamente basándose en los costos y beneficios de diferentes tipos de errores. Un organismo que está hambriento y para quien un hit (detectar correctamente que su acción produjo comida) vale mucho, será más liberal al atribuir causalidad a sus acciones, aceptando un incremento en falsas alarmas como costo inevitable. Este ajuste del criterio de decisión, predicho por la teoría de detección de señales, demuestra que la atribución de causalidad es un proceso inferencial sofisticado, no un registro pasivo de contigüidades.

Las conclusiones de este capítulo complementan y extienden las del capítulo anterior. En ambos casos—asignación de crédito a estímulos y a respuestas—la contigüidad temporal juega un papel, pero no es ni necesaria ni suficiente. Los organismos son detectores de estructura causal más profunda: contingencias estadísticas, correlaciones a largo plazo, reducción de incertidumbre. Los sesgos inductivos—relevancia biológica, novedad, conducta inducida, sistemas de comportamiento—estructuran el espacio de búsqueda, haciendo el problema computacional tratable. Y la selección opera no sobre contigüidades momentáneas sino sobre patrones de covariación que revelan las verdaderas estructuras causales del ambiente.

Estos principios nos preparan para el próximo capítulo, donde estudiaremos modelos formales que capturan matemáticamente estos procesos. El modelo de Rescorla-Wagner, originalmente propuesto para condicionamiento clásico, puede extenderse al aprendizaje de respuestas. Los algoritmos de aprendizaje por refuerzo en inteligencia artificial—diferencias temporales, Q-learning—formalizan precisamente estos principios de asignación de crédito temporal y detección de contingencia. Veremos que la distinción entre escalas moleculares y molares tiene paralelos directos en algoritmos de aprendizaje basados en valor versus basados en política. Y el concepto de conducta inducida como estructura innata que guía el aprendizaje tiene paralelos con el diseño de arquitecturas de red con sesgos inductivos en machine learning contemporáneo.

El estudio del aprendizaje de respuestas no es solo historia de la psicología. Es el estudio de cómo agentes autónomos—biológicos o artificiales—pueden descubrir y explotar la estructura causal de su ambiente para maximizar resultados valiosos. Los principios que emergen son generales y siguen siendo fundamentales para nuestra comprensión del comportamiento adaptativo y el diseño de sistemas artificiales inteligentes.

---

## Lecturas Recomendadas

**Artículos Clásicos Fundamentales:**

- Thorndike, E. L. (1898). "Animal intelligence: An experimental study of the associative processes in animals." *Psychological Review Monograph Supplements*, 2(4), i-109. [El trabajo original que introdujo la Ley del Efecto—históricamente esencial]

- Skinner, B. F. (1948). "'Superstition' in the pigeon." *Journal of Experimental Psychology*, 38, 168-172. [Artículo clásico sobre conducta "supersticiosa"—importante aunque la interpretación es cuestionable]

- Staddon, J. E. R., & Simmelhag, V. L. (1971). "The 'superstition' experiment: A reexamination of its implications for the principles of adaptive behavior." *Psychological Review*, 78, 3-43. [Análisis detallado que introduce conducta inducida—lectura esencial]

**Sobre Contingencia y Demora:**

- Dickinson, A., Watt, A., & Griffiths, W. J. H. (1992). "Free-operant acquisition with delayed reinforcement." *Quarterly Journal of Experimental Psychology*, 45B, 241-258. [Estudio definitivo sobre efectos de demora—diseño experimental impecable]

- Hammond, L. J. (1980). "The effect of contingency upon the appetitive conditioning of free-operant behavior." *Journal of the Experimental Analysis of Behavior*, 34, 297-304. [Demostración clara de contingencia vs. contigüidad]

- Lattal, K. A., & Gleeson, S. (1990). "Response acquisition with delayed reinforcement." *Journal of Experimental Psychology: Animal Behavior Processes*, 16, 27-39. [Control elegante de contigüidad accidental]

**Sobre Percepción de Causalidad:**

- Killeen, P. R. (1978). "Superstition: A matter of bias, not detectability." *Science*, 199, 88-90. [Experimento brillante sobre percepción de causalidad y teoría de detección de señales]

- Killeen, P. R. (1981). "Incentive theory." *Nebraska Symposium on Motivation*, 29, 169-216. [Desarrollo teórico más amplio sobre motivación e incentivos]

**Perspectiva Molar:**

- Baum, W. M. (2002). "From molecular to molar: A paradigm shift in behavior analysis." *Journal of the Experimental Analysis of Behavior*, 78, 95-116. [Articulación clara de la distinción molecular-molar]

- Baum, W. M. (2012). "Rethinking reinforcement: Allocation, induction, and contingency." *Journal of the Experimental Analysis of Behavior*, 97, 101-124. [Análisis contemporáneo que integra múltiples perspectivas]

**Textos de Referencia:**

- Domjan, M. (2014). *The Principles of Learning and Behavior* (7th ed.). Cengage Learning. [Capítulos 5-6: Excelente cobertura equilibrada de condicionamiento instrumental]

- Pearce, J. M. (2008). *Animal Learning and Cognition* (3rd ed.). Psychology Press. [Capítulos 3-4: Perspectiva británica contemporánea sobre aprendizaje instrumental]

**Para Profundizar:**

- Gallistel, C. R., & Gibbon, J. (2000). "Time, rate, and conditioning." *Psychological Review*, 107, 289-344. [Análisis profundo del papel del tiempo—perspectiva alternativa al asociacionismo tradicional]

- Timberlake, W., & Lucas, G. A. (1989). "Behavior systems and learning: From misbehavior to general principles." In S. B. Klein & R. R. Mowrer (Eds.), *Contemporary Learning Theories: Instrumental Conditioning Theory and the Impact of Biological Constraints on Learning* (pp. 237-275). Erlbaum. [Presentación detallada de la teoría de sistemas de comportamiento aplicada al aprendizaje operante]

- Killeen, P. R., & Pellón, R. (2013). "Adjunctive behaviors are operants." *Learning & Behavior*, 41, 1-24. [Análisis moderno de conducta inducida—actualización de Staddon & Simmelhag]

---

**Fin del Capítulo 9**
