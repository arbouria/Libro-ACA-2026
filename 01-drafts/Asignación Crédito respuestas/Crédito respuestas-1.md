# # Capítulo 9: Asignación de Crédito para Respuestas
## Del Control Predictivo al Control Causal

## Objetivos del Capítulo

Al finalizar este capítulo, deberás ser capaz de:

1. Explicar la diferencia fundamental entre aprender relaciones predictivas (E→SBI) y relaciones causales (R→SBI)
2. Comprender por qué el problema de asignación de crédito para respuestas requiere dos mecanismos complementarios: generación de variabilidad y selección
3. Evaluar críticamente la Ley del Efecto de Thorndike y sus limitaciones
4. Distinguir entre contigüidad temporal y contingencia estadística, y explicar por qué la contigüidad no es ni necesaria ni suficiente
5. Describir los experimentos que demuestran que los organismos son sensibles a relaciones causales, no solo temporales
6. Explicar el concepto de "conducta inducida" y su papel como sesgo inductivo
7. Comprender cómo los organismos perciben causalidad y cómo esta percepción es modulada por costos y beneficios

---

## Introducción

El acceso a sucesos biológicamente importantes es fundamental para la supervivencia y reproducción de los organismos. En el capítulo anterior vimos cómo los organismos que pueden predecir confiablemente la ocurrencia de SBIs tienen una ventaja adaptativa. Aprender que un cielo encapotado predice una fuerte lluvia le permite a un individuo anticiparse y prepararse correctamente para ella. De igual forma, escuchar un rugido le permite a una presa prepararse para un posible ataque. 

Sin embargo, hay algo crucial que falta en esta historia: **el organismo no tiene control sobre estos eventos**. Puede predecir cuándo lloverá, pero no puede alterar que llueva. Puede predecir que detrás del rugido haya un depredador, pero no puede modificar su presencia. La predicción permite *anticipación*, pero no *control*.

Uno de los saltos más importantes en la historia evolutiva fue la emergencia de mecanismos biológicos que, a través de la acción y la interacción con el entorno, permiten a los organismos **controlar** la ocurrencia de sucesos biológicamente importantes. Cuando una respuesta adquiere valor predictivo de un reforzador, se añade algo fundamentalmente nuevo: la posibilidad de producir el SBI, no solo anticiparlo.

Estos mecanismos se encuentran estrechamente asociados a un componente específico de la estructura causal de los entornos: las relaciones que describen cuáles acciones de un organismo son exitosas para obtener mayores opciones de acceso a SBIs. Ejemplos cotidianos de estas **relaciones que describen acciones exitosas** abundan en nuestra vida:

- Los **contratos laborales** especifican las acciones a seguir para acceder a un monto de dinero (mayores opciones de SBIs)
- Las **reglas de transporte público** definen qué acciones llevar a cabo para tomar un autobús
- Las **normas sociales** especifican las acciones requeridas para iniciar una relación amorosa  
- El **adiestramiento de mascotas** establece qué acciones les otorgan una comida especial
- La **ecología de cada especie** determina las acciones que facilitan acceso a alimentos y permiten escapar de depredadores

Desde la psicología, nos preguntamos: **¿Cómo logra un organismo reconocer estas estructuras causales?** Específicamente, ¿cómo puede determinar qué acción específica, entre muchas posibilidades, es la responsable del resultado deseado (el SBI)?

En los libros de texto, al estudio de la respuesta a esta pregunta se le conoce como *condicionamiento instrumental* o *condicionamiento operante*. En estas notas abordaremos su estudio con base en el mismo grupo de principios con los que abordamos el condicionamiento clásico en el capítulo anterior. Veremos que, aunque el mecanismo fundamental es similar (sensibilidad a correlaciones estadísticas), el problema de las respuestas tiene matices únicos que revelan la sofisticación del aprendizaje adaptativo.

---

## Parte I: El Problema Computacional

### Los Orígenes: Thorndike y la Ley del Efecto

Antes de describir cómo se aplican los principios de asignación de crédito a las respuestas, revisemos el estudio original que inauguró esta área de investigación. Al inicio del siglo XX, Edward Thorndike (1898) condujo una serie de estudios con gatos que revolucionarían nuestra comprensión del aprendizaje.

#### El Aparato: La Caja Problema

Thorndike diseñó una variedad de "cajas problema" de las cuales un gato encerrado podría escapar activando dispositivos como un cerrojo o una palanca. Fuera de la caja había comida visible—un incentivo poderoso para el gato hambriento.

**Procedimiento**:
1. Gato encerrado en la caja, puede ver la comida afuera
2. Debe descubrir cómo operar el mecanismo de escape (ej. jalar una cuerda)
3. Al escapar, obtiene acceso a la comida
4. El gato es devuelto a la caja para un nuevo ensayo
5. Medida: **tiempo para escapar** en cada ensayo

**Observaciones clave**:

Al inicio, los gatos intentaban un número grande de respuestas sin aparente dirección: arañar paredes, maullar, caminar en círculos, morder los barrotes. Eventualmente, por aparente accidente, operaban el dispositivo que abría la puerta. La puerta se abría, el gato obtenía la comida.

Pero lo fascinante ocurría en ensayos subsecuentes: el tiempo para escapar **disminuyó gradualmente** a través de los ensayos. Las respuestas incorrectas se volvían menos frecuentes. La respuesta correcta emergía cada vez más rápido. Después de varios ensayos, el gato ejecutaba de forma casi inmediata la respuesta que fue exitosa para escapar.

Thorndike caracterizó esta ejecución como una de **ensayo y error**: el gato intentaba diferentes respuestas (ensayos) y las descartaba si no lo llevaban a salir de la caja (error).

**Figura 9.1 debe mostrar**: Curva de aprendizaje típica de Thorndike
- Eje X: Número de ensayo
- Eje Y: Tiempo para escapar (segundos)
- Curva descendente mostrando reducción gradual del tiempo
- Ilustrar variabilidad dentro de la tendencia general

#### La Ley del Efecto

Para entender estos resultados, Thorndike propuso un principio que se conoce como la **Ley del Efecto**:

> "En la presencia de un estímulo (situación, contexto) pueden ocurrir una multitud de respuestas. Aquella que vaya seguida de un estado de cosas satisfactorio tendrá que ser la que se asocia (conecta, selecciona) con el estímulo."

En terminología moderna:
- "Estímulo" = contexto o situación discriminativa
- "Estado de cosas satisfactorio" = reforzador positivo (SBI apetitivo)
- "Asocia/conecta" = incremento en la probabilidad de la respuesta

**El mecanismo implícito**: La *contigüidad temporal* entre respuesta y reforzador fortalece la conexión estímulo-respuesta.

### Análisis del Problema: Dos Observaciones, Dos Mecanismos

Los resultados de Thorndike pueden descomponerse en dos observaciones que requieren explicación:

**Observación 1**: El conjunto de respuestas variadas que el gato lleva a cabo *antes* de emitir la respuesta correcta.
- ¿De dónde vienen estas respuestas?
- ¿Por qué el gato no se queda inmóvil esperando?
- ¿Qué determina el repertorio de respuestas que el gato intenta?

**Observación 2**: Después de varios ensayos, el gato ejecuta de forma casi exclusiva e inmediata la respuesta exitosa.
- ¿Cómo se selecciona la respuesta correcta entre todas las probadas?
- ¿Por qué desaparecen las respuestas incorrectas?
- ¿Qué marca a una respuesta como "la correcta"?

Recordemos del capítulo anterior que el encuentro inesperado con un SBI echa a andar dos mecanismos complementarios:

**Mecanismo 1**: Control del comportamiento apropiado para la interacción con y búsqueda del SBI (conducta inducida)

**Mecanismo 2**: Aprendizaje que permite predecir y controlar su futura ocurrencia (asignación de crédito)

Estos dos mecanismos corresponden a dos tipos de sesgos inductivos que vimos en el Capítulo 8:

**Sesgo Tipo 1**: Determina qué elementos (respuestas) conforman el espacio de candidatos
- Análogo a mutación y recombinación en evolución
- Genera variabilidad sobre la cual operará la selección

**Sesgo Tipo 2**: Determina cuál elemento dentro del espacio considerar primero  
- Análogo a selección natural en evolución
- Opera sobre la variabilidad generada por el Sesgo Tipo 1

La Ley del Efecto de Thorndike prioriza a la **contigüidad** como el factor que determina tanto el espacio de candidatos como el orden de selección. Pero crucialmente, **no toma en cuenta el origen de las respuestas** que anteceden al "estado de cosas satisfactorio". Esta omisión, como veremos, es fundamental.

En lo que resta del capítulo revisaremos la evidencia sobre el papel de la contigüidad en la asignación de crédito para respuestas, y descubriremos que la historia es más compleja y fascinante de lo que Thorndike imaginó.

---

## Parte II: El Reinado de la Contigüidad

### Skinner y el Experimento de "Superstición"

En 1948, B.F. Skinner publicó los resultados de un pequeño pero influyente experimento diseñado para demostrar la suficiencia de la contigüidad para el aprendizaje de respuestas.

#### Procedimiento

**Sujetos**: Palomas privadas de comida

**Procedimiento**: 
- Comida presentada automáticamente cada 15 segundos
- **Crucial**: Independientemente del comportamiento de la paloma
- Observación del comportamiento entre entregas de comida

#### Resultados

Skinner observó que, a pesar de que la comida era independiente del comportamiento, cada paloma desarrollaba un patrón conductual **estereotipado** que repetía consistentemente. Pero lo notable era que estos patrones **diferían entre palomas**:

- Una paloma giraba en sentido antihorario
- Otra paloma movía la cabeza como péndulo  
- Otra picoteaba el piso en un lugar específico
- Otra daba cuartos de vuelta
- Etc.

**Figura 9.2 debe mostrar**: Fotografías del experimento original de Skinner (1948)
- Diferentes palomas mostrando sus "supersticiones" individuales
- Caption explicando la variabilidad entre sujetos

#### Interpretación de Skinner

Skinner explicó estos resultados así:

> "Para cada ave, una respuesta ocurría de forma **accidental** inmediatamente antes del refuerzo, y esa contigüidad era responsable del fortalecimiento de dicha respuesta. Una vez fortalecida, la respuesta tenía mayor probabilidad de ocurrir nuevamente cerca del siguiente refuerzo, creando un ciclo de auto-fortalecimiento."

De esta interpretación, Skinner concluyó algo que parecía confirmar la suficiencia de la contigüidad:

> "Decir que un reforzador es contingente sobre una respuesta no significa otra cosa que decir que 'se presenta después de la respuesta'. Presumiblemente, el condicionamiento ocurre únicamente debido a la relación temporal, expresada en términos de la proximidad entre la respuesta y el reforzador."

Nótese que Skinner usa el término **"contingente"** pero lo define como **contigüidad temporal**. Esta confusión terminológica ha persistido en muchos textos. Vale la pena ser explícitos:

**Contigüidad**: Proximidad temporal. A y B ocurren cercanos en el tiempo.
**Contingencia**: Dependencia estadística. P(B|A) ≠ P(B|no-A).

### Problemas con la Interpretación

La interpretación de Skinner, aunque elegante, tiene tres problemas serios que no fueron evidentes hasta estudios posteriores:

**Problema 1 - Variabilidad entre palomas**: Si el mecanismo es puramente contigüidad accidental, ¿por qué cada paloma desarrolla un patrón diferente? Si todas experimentan el mismo protocolo (comida cada 15s), ¿por qué no todas desarrollan la misma "superstición"?

**Problema 2 - Consistencia dentro de palomas**: ¿Por qué el patrón se estabiliza en lugar de seguir cambiando con nuevas contigüidades accidentales? Después de todo, muchas otras respuestas también preceden accidentalmente al reforzador.

**Problema 3 - Origen de respuestas**: ¿Qué determina qué respuestas están disponibles para ser "accidentalmente" fortalecidas? ¿Por qué las palomas no desarrollan respuestas completamente arbitrarias como pararse en una pata o vocalizar de cierta manera?

Estos problemas apuntan a una laguna fundamental en la teoría: **el origen de las respuestas candidatas**.

---

## Parte III: Cuestionando la Suficiencia de la Contigüidad

### Staddon y Simmelhag: Conducta Inducida

En 1971, Staddon y Simmelhag publicaron una réplica del experimento de Skinner con una diferencia crucial: en lugar de observaciones esporádicas, registraron exhaustivamente el comportamiento de las palomas **a lo largo de todo el intervalo** entre entregas de comida.

#### Procedimiento Mejorado

- Palomas hambrientas
- Comida cada 12 segundos, independientemente del comportamiento
- **Crucial**: Registro continuo y sistemático de todas las respuestas
- Clasificación detallada de tipos de respuesta

#### Descubrimientos Revolucionarios

Los resultados contradijeron la interpretación de Skinner y revelaron algo fascinante:

**Descubrimiento 1 - Organización temporal**: El comportamiento no era aleatorio ni estereotipado de forma arbitraria. Se organizaba **sistemáticamente a lo largo del intervalo** entre reforzadores.

**Descubrimiento 2 - Dos clases de respuestas**:

**Respuestas Terminales**: Alta probabilidad hacia el *final* del intervalo
- R1: Orientarse hacia la pared del comedero
- R7: Picotear en la pared del comedero
- Estas respuestas son apropiadas para *consumir* el reforzador

**Respuestas Interinas**: Alta probabilidad hacia la *mitad* del intervalo
- R3: Picotear en el piso
- R4: Dar un cuarto de vuelta
- R8: Moverse cerca de la pared del comedero
- Estas respuestas son apropiadas para *búsqueda* o actividad general

**Figura 9.3 debe mostrar** (basada en Staddon & Simmelhag, 1971):
- Eje X: Tiempo en el intervalo (0-12 segundos)
- Eje Y: Probabilidad de ocurrencia de cada respuesta
- Múltiples curvas para R1, R3, R4, R7, R8
- Mostrar claramente el patrón terminal vs. interino

#### Replicación con Ratas

Crucialmente, Staddon y Simmelhag replicaron el estudio con **ratas** y observaron el mismo patrón: agrupación de respuestas en clases terminales e interinas, organización temporal del comportamiento.

### Conclusiones Revolucionarias

De los resultados de Staddon y Simmelhag podemos extraer dos conclusiones, una negativa y otra positiva:

**Conclusión Negativa (sobre Skinner)**:
En experimentos donde no existe relación causal entre respuesta y SBI, el reforzador **no selecciona** la respuesta que accidentalmente le antecede. Esto contradice la idea de que la contigüidad es suficiente para el aprendizaje de respuestas.

**Conclusión Positiva (sobre conducta inducida)**:
La mera presentación de un SBI **induce** un conjunto tipificado de respuestas, y la periodicidad de su presentación **organiza** el comportamiento alrededor del tiempo.

### Implicaciones: El Sesgo Inductivo Tipo 1

La conducta inducida resuelve el misterio del origen de las respuestas. Es un **sesgo inductivo del Tipo 1**: determina qué respuestas conforman el espacio de candidatos para la asignación de crédito.

**Características de la conducta inducida**:

1. **Apropiada al tipo de reforzador**: Respuestas relacionadas con comida para reforzadores alimenticios, respuestas relacionadas con agua para reforzadores hídricos, etc.

2. **Organizada temporalmente**: Respuestas de búsqueda/exploración temprano en el intervalo, respuestas de aproximación/consumación cerca del reforzador

3. **Sensible a affordances**: Depende de qué acciones permite el contexto físico

4. **No es fija ni refleja**: Varía entre individuos según experiencia y contexto específico

5. **Reduce dramáticamente el espacio de búsqueda**: De infinitas respuestas posibles, solo un subconjunto biológicamente relevante es inducido

**Analogía evolutiva refinada**:

| Evolución | Aprendizaje Instrumental |
|-----------|-------------------------|
| Mutación genera variabilidad genética | Conducta inducida genera variabilidad conductual |
| Recombinación crea nuevas combinaciones | Organización temporal crea patrones |
| Selección natural opera sobre fenotipos | Contingencia R→SBI opera sobre respuestas |
| Herencia preserva genes exitosos | Memoria preserva respuestas exitosas |

Pero esto solo resuelve el problema del **origen** de las respuestas (Observación 1 de Thorndike). Aún falta explicar la **selección** (Observación 2). Y para eso, necesitamos examinar críticamente el papel de la contigüidad.

---

## Parte IV: Cuestionando la Necesidad de la Contigüidad

Si la contigüidad fuera **necesaria** para el aprendizaje de respuestas, entonces introducir una demora entre respuesta y reforzador debería eliminar el aprendizaje. Veamos qué encontraron los experimentos.

### Definiendo Contigüidad Operacionalmente

Para estudiar sistemáticamente el papel de la contigüidad, es necesario especificar la **ventana temporal** que define a dos eventos como contiguos:
- ¿Cuándo podemos considerar que un suceso es contiguo?
- Si el SBI ocurre 1 segundo después de la respuesta, ¿es contiguo?
- ¿Y 2 segundos? ¿10 segundos? ¿Dónde está el límite?

La estrategia teórica-experimental fue:
- Considerar contigüidad **estricta** como ventana de ~0 segundos
- Estudiar el efecto de demoras crecientes como **degradación de contigüidad**
- Crucial: Mantener la **dependencia causal** respuesta→SBI mientras se varía la demora

### Experimento 1: Dickinson et al. (1991) - Demora del Reforzamiento

#### Diseño Experimental

**Sujetos**: Ratas sin experiencia previa con el procedimiento

**Procedimiento**:
- Cada respuesta de apretar palanca produce un SBI después de una **demora fija**
- Durante la demora, la rata puede responder de nuevo, lo cual añade otro SBI (con la misma demora)
- Grupos con diferentes demoras: 2, 4, 8, 16, 32, o 64 segundos
- Medida: Tasa de presión de palanca (respuestas por minuto)

**Característica crucial**: Con este procedimiento es posible que ocurran **contigüidades accidentales**:
- Rata presiona palanca (t = 0)
- Reforzador programado para t = 16s  
- Rata presiona otra vez (t = 15.5s)
- Reforzador aparece (t = 16s)
- ¡Ahora hay contigüidad accidental entre segunda respuesta y reforzador!

Para descartar que el aprendizaje se deba a contigüidades accidentales en lugar de la dependencia causal, Dickinson incluyó un **grupo control yokeado**:

**Grupo Control (Yoked)**: Otras ratas en cámaras separadas reciben exactamente los mismos reforzadores, en los mismos tiempos, que las del grupo experimental—pero **independientemente de su comportamiento**.

**Lógica del control**:
- Si contigüidad accidental es suficiente → ambos grupos deberían aprender igual
- Si dependencia R→SBI es crucial → solo grupo experimental debería aprender

#### Resultados

**Figura 9.4 debe mostrar** (basada en Dickinson et al., 1991):

*Panel A (izquierda)*:
- Eje X: Demora experimentada (segundos): 0, 2, 4, 8, 16, 32, 64
- Eje Y: Presiones de palanca por minuto  
- Dos líneas:
  - **Grupo Master** (contingente): ~20/min en demora 0, disminuye gradualmente a ~2/min en 32s, ~0 en 64s
  - **Grupo Yoke** (no-contingente): ~0-2/min plano a través de todas las demoras

*Panel B (derecha)* - Tres sub-paneles para demoras de 16s, 32s, 64s:
- Eje X: Sesiones sucesivas (1-20)
- Eje Y: Presiones de palanca por minuto
- En cada panel: Línea Master vs. Yoke
- Mostrar adquisición gradual en Master, ausencia en Yoke

#### Interpretación

**1. La contigüidad NO es suficiente**: 
Las ratas del grupo yoked, a pesar de experimentar contigüidades accidentales entre sus respuestas y los reforzadores, **no aprendieron** a presionar la palanca. La tasa de respuesta permaneció cerca de cero.

**2. La contigüidad estricta NO es necesaria**:
Las ratas del grupo master aprendieron incluso con demoras de **32 segundos**. El aprendizaje fue más débil con demoras largas, pero ocurrió.

**3. La dependencia causal es crucial**:
El factor determinante no es cuán cerca temporalmente está el reforzador de la respuesta, sino si existe una **relación de dependencia** entre ellos: P(SBI|R) > P(SBI|no-R).

### Experimento 2: Lattal & Gleeson (1990) - Eliminando Contigüidad Accidental

Un problema potencial del experimento de Dickinson es que, aunque el grupo yoked controla por contigüidad accidental en promedio, el grupo experimental aún podría aprender parcialmente por contigüidades accidentales además de la dependencia causal.

Lattal y Gleeson diseñaron un experimento más estricto para **garantizar** la ausencia de contigüidad.

#### Diseño Experimental

**Sujetos**: Palomas

**Procedimiento - DRO modificado** (Differential Reinforcement of Other behavior):
- Picar la tecla detona una demora de 10 segundos
- Después de 10s → reforzador de comida
- **PERO** solo si la paloma **NO ha picado** durante esos 10 segundos
- Si pica antes de que pasen los 10s → reloj se reinicia

**Garantía lógica**: Este diseño garantiza una demora real de **al menos 10 segundos** entre cualquier respuesta y el reforzador. Es **imposible** que haya contigüidad accidental.

Si la contigüidad fuera necesaria, este procedimiento no debería generar aprendizaje.

#### Resultados

**Figura 9.5 debe mostrar** (basada en Lattal & Gleeson, 1990):
- Cinco palomas individuales en paneles separados (numeradas 3490, 3494, 3538, 3630, 4230)
- Eje X: Sesiones sucesivas
- Eje Y: Respuestas por minuto (escala logarítmica)
- Para todas las palomas: **adquisición clara** a través de sesiones

Las palomas aprendieron la respuesta de picar la tecla incluso cuando era **imposible** que hubiera contigüidad entre respuesta y reforzador.

#### Conclusión Contundente

La contigüidad estricta entre respuesta y reforzador **no es necesaria** para el aprendizaje. Lo que importa es la **dependencia estadística**: ¿la respuesta aumenta la probabilidad del reforzador?

---

## Parte V: La Contingencia como Factor Crucial

Los experimentos de Dickinson y Lattal demuestran que la contigüidad no es necesaria. Pero ¿qué determina entonces si una respuesta se aprende? La respuesta es: la **contingencia estadística**.

### Experimento 3: Hammond (1980) - Manipulando Contingencias

Hammond diseñó un experimento elegante para evaluar directamente si los organismos son sensibles a la contingencia (relación estadística) o solo a la contigüidad.

#### Diseño Experimental

**Estrategia - Discretización del tiempo**:
- El tiempo continuo se divide en intervalos de 1 segundo
- En cada intervalo, la rata puede o no emitir una respuesta
- Esto permite manipular independientemente:
  - P(reforzador | respuesta)
  - P(reforzador | no-respuesta)

**Grupos experimentales**:

| Grupo | P(Ref\|R) | P(Ref\|no-R) | Contingencia | Contigüidad |
|-------|-----------|--------------|--------------|-------------|
| 1     | 0.05      | 0.01         | Positiva fuerte | Idéntica en todos |
| 2     | 0.05      | 0.05         | **Cero** (no-contingente) | Idéntica en todos |
| 3     | 0.05      | 0.00         | Positiva máxima | Idéntica en todos |

**Punto crucial**: Todos los grupos experimentan la *misma* contigüidad cuando ocurre un reforzador (aparece 1s después de una respuesta en intervalos donde responden). Lo que difiere es la *contingencia*—la relación estadística.

**Predicciones**:
- Si solo contigüidad importa → los tres grupos deberían aprender igual
- Si contingencia importa → solo Grupos 1 y 3 deberían aprender, no Grupo 2

#### Resultados

**Figura 9.6 debe mostrar** (basada en Hammond, 1980):
- Tres paneles para grupos 0.05-0.01, 0.05-0.05, 0.05-0.0
- Eje X: Sesiones (1-65)
- Eje Y: Respuestas por hora
- Patrón claro:
  - **Grupo 1 (0.05-0.01)**: Adquisición gradual, estabiliza ~2500 resp/hora
  - **Grupo 2 (0.05-0.05)**: No adquisición, permanece ~100-300 resp/hora
  - **Grupo 3 (0.05-0.0)**: Adquisición más rápida y fuerte, >3000 resp/hora

#### Interpretación

A pesar de contigüidad idéntica en los tres grupos, **solo hay aprendizaje cuando existe contingencia positiva**. 

El Grupo 2, donde P(Ref|R) = P(Ref|no-R), no muestra aprendizaje. La respuesta no tiene **valor predictivo ni causal** porque es igualmente probable que el reforzador aparezca sin la respuesta.

**Implicación crucial**: Los animales no están simplemente formando asociaciones entre eventos contiguos. Están **computando la relación estadística** entre sus acciones y las consecuencias.

### Síntesis: Contigüidad vs. Contingencia

Los tres experimentos (Dickinson, Lattal, Hammond) convergen en una conclusión clara:

**La contigüidad NO es necesaria**: Demoras de 10-32 segundos no impiden aprendizaje (Dickinson, Lattal)

**La contigüidad NO es suficiente**: Contigüidades accidentales no producen aprendizaje sin contingencia (Dickinson, Hammond)

**Lo que importa es la contingencia**: P(SBI|R) vs. P(SBI|no-R)

Esto es exactamente paralelo a lo que Rescorla demostró para estímulos (Cap. 8): **los organismos son sensibles a correlaciones estadísticas, no solo a asociaciones temporales**.

---

## Parte VI: Percepción de Causalidad

Los resultados anteriores demuestran que los organismos *responden apropiadamente* a diferentes contingencias. Pero hay una pregunta más profunda: **¿Pueden los organismos discriminar directamente si un evento fue causado por ellos o no?**

### El Experimento de Killeen: Discriminación de Causalidad

Peter Killeen (1978) diseñó un experimento brillante para evaluar si las palomas pueden **percibir causalidad**—distinguir eventos que ellas causan de eventos independientes.

#### Diseño Experimental

**Tarea**: Discriminación de causa vs. no-causa

**Procedimiento**:
1. Palomas pican una **tecla central iluminada**
2. Con probabilidad p = 0.05, cada picotazo **apaga** la tecla central y **enciende** dos teclas laterales
3. **Crucial**: La computadora también genera **"pseudo-picotazos"** a la misma tasa que la paloma
4. Los pseudo-picotazos también tienen p = 0.05 de causar el cambio de luces

**La tarea de discriminación**:
- Si el cambio fue causado por un picotazo *real* → picar tecla **DERECHA** → comida
- Si el cambio fue causado por un pseudo-picotazo → picar tecla **IZQUIERDA** → comida  
- Respuestas incorrectas → timeout breve (apagón)

**Manipulación experimental**: Killeen varió la **cantidad de comida** (duración de acceso al comedero) para respuestas correctas en diferentes condiciones.

**La pregunta central**: 
1. ¿Pueden las palomas discriminar eventos que ellas causan de eventos independientes?
2. Si pueden, ¿cómo afectan los payoffs a su criterio de respuesta?

#### Conexión con Teoría de Detección de Señales

Este diseño es formalmente idéntico a una tarea de **Teoría de Detección de Señales** (Cap. 6):

**Señal presente** = Cambio causado por respuesta real  
**Señal ausente** = Cambio causado por pseudo-respuesta

**Hit** = Reportar correctamente "yo lo causé" cuando sí lo causaste
**False Alarm** = Reportar "yo lo causé" cuando fue la computadora  
**Correct Rejection** = Reportar correctamente "no lo causé" cuando fue la computadora
**Miss** = Reportar "no lo causé" cuando sí lo causaste

Recordemos del Cap. 6: hay una relación entre hits y falsas alarmas determinada por:
- **Discriminabilidad (d')**: ¿Qué tan fácil es distinguir señal de ruido?
- **Criterio (β)**: ¿Cuán conservador/liberal es el sujeto al reportar "señal presente"?

**Predicciones basadas en TDS**:
1. Si hay discriminabilidad: P(Hit) > P(FA)
2. Si payoff por hits aumenta: Criterio se vuelve más liberal (más hits pero también más FAs)
3. La curva ROC (hits vs. FAs) debería estar por encima de la diagonal

#### Resultados

**Resultado 1 - Discriminabilidad de Causalidad**

**Figura 9.7 debe mostrar** (basada en Killeen, 1978):
- Cuatro paneles para palomas S1, S2, S3, S4
- **Curvas ROC**: Eje X = P(False Alarm), Eje Y = P(Hit)  
- Múltiples puntos por paloma = diferentes magnitudes de payoff
- Diagonal punteada = ejecución al azar
- **Resultado**: Todas las curvas claramente por encima de la diagonal

**Interpretación**: 
- Las palomas **pueden discriminar** entre eventos que ellas causan vs. eventos independientes
- La discriminabilidad es **mejor que azar** (d' > 0)
- Esto demuestra **percepción activa de agencia**

**Resultado 2 - Sensibilidad a Payoffs**

Dentro de cada paloma, los puntos se desplazan a lo largo de la curva ROC según el payoff:
- **Payoff bajo** → Criterio conservador → Menos hits, menos FAs
- **Payoff alto** → Criterio liberal → Más hits, más FAs

**Interpretación**: La percepción de causalidad no es un proceso automático todo-o-nada. Es una **decisión bajo incertidumbre** modulada por costos y beneficios, exactamente como predice TDS.

**Resultado 3 - Ventana Temporal de Causalidad**

**Figura 9.8 debe mostrar** (basada en Killeen, 1978):
- Eje X: Tiempo entre pseudo-respuesta y evento (segundos): 0.2, 0.4, 0.6, 0.8, 1.0
- Eje Y: Probabilidad de Falsa Alarma  
- Múltiples curvas = diferentes magnitudes de comida (1.8s, 2.3s, 2.8s, 3.8s de acceso)
- **Patrón**: 
  - Falsas alarmas **disminuyen** con mayor intervalo temporal
  - Falsas alarmas **aumentan** con mayor payoff

**Interpretación**:

1. **Ventana temporal de causalidad**: Las palomas tratan eventos dentro de ~0.2-0.4 segundos de su respuesta como potencialmente causados por ellas. Más allá de ~1 segundo, es claramente "no causado por mí".

2. **Influencia de payoffs**: Cuando la recompensa es muy grande, las palomas son más "liberales"—dispuestas a cometer falsas alarmas a cambio de no perder hits.

3. **Racionalidad adaptativa**: Este patrón es exactamente lo que predice TDS y es adaptativamente sensato. Si los costos de un error (Miss) son grandes y los costos del otro error (FA) son pequeños, es racional ser liberal.

### Implicaciones Profundas

El experimento de Killeen tiene consecuencias que van más allá del aprendizaje instrumental:

**1. Percepción activa de agencia**: 
Los organismos tienen un **mecanismo perceptual** para monitorear qué eventos en el mundo son consecuencia de sus acciones vs. independientes de ellas. No es solo "si refuerzo entonces responder más"—es "puedo distinguir qué causé yo de qué no".

**2. Integración con marcos generales de decisión**:
La asignación de crédito no es un módulo aislado. Está **integrada** con sistemas generales de decisión bajo incertidumbre (TDS, teoría de la utilidad esperada, etc.).

**3. Explicación de "supersticiones"**:
Cuando los organismos muestran conducta "supersticiosa" (como en el experimento de Skinner), puede deberse a:
- Alta liberalidad en el criterio (payoffs favorecen ser liberal)
- No a una falla del mecanismo de discriminación

**4. Preparación para aprendizaje secuencial**:
Esta capacidad de rastrear relaciones causales entre acciones y consecuencias es fundamental para aprender en entornos donde las consecuencias son **distales**—tema del Bloque V sobre Aprendizaje por Refuerzo Secuencial.

---

## Parte VII: Síntesis Conceptual

### El Cuadro Completo: Dos Mecanismos Complementarios

La asignación de crédito para respuestas involucra **dos mecanismos complementarios** que trabajan en conjunto:

**Mecanismo 1 - Inducción de Variabilidad** (Sesgo Inductivo Tipo 1):
- Presentación de un SBI inesperado **induce** un conjunto de respuestas estereotipadas
- Estas respuestas son **apropiadas** al tipo de SBI y al tiempo transcurrido
- Organización en respuestas **terminales** (consumatorias) e **interinas** (exploratorias)
- Reduce dramáticamente el espacio de búsqueda
- Proporciona el "pool" de respuestas candidatas

**Mecanismo 2 - Selección por Contingencia** (Sesgo Inductivo Tipo 2):
- De las respuestas inducidas, aquellas que tienen **relación estadística** con el SBI se fortalecen
- Sensibilidad a **P(SBI|R) vs. P(SBI|no-R)**, no solo a contigüidad
- El organismo puede **percibir activamente** si eventos son causados por él
- Esta percepción es modulada por **costos y beneficios** (integración con TDS)

### Respondiendo las Dos Observaciones de Thorndike

Ahora podemos dar respuestas completas a las dos observaciones de los experimentos originales:

**Observación 1 - Variabilidad inicial de respuestas**:
- **No es aleatoria**: Es conducta inducida por el SBI (escape + comida)
- Las respuestas son **apropiadas** al contexto (arañar, jalar, empujar son affordances del ambiente de la caja)
- Organización temporal: Exploración/búsqueda → aproximación → consumación

**Observación 2 - Selección de la respuesta exitosa**:
- **No es solo contigüidad**: La respuesta exitosa tiene **contingencia** positiva con el reforzador
- P(escape | jalar cuerda) >> P(escape | no jalar cuerda)
- Las respuestas que no tienen esta relación se extinguen (no porque "no fueron contiguas" sino porque "no fueron contingentes")

### Conexiones con el Marco Conceptual

#### Relación con el Capítulo 2: Propiedades Estadísticas del Entorno

Los hallazgos de este capítulo se conectan directamente con las propiedades del entorno que favorecen el aprendizaje:

**Propiedad 4 - Autocorrelación temporal**: 
- Los estados del mundo persisten y cambian gradualmente
- **Relevancia**: La organización temporal de la conducta inducida (interina→terminal) explota esta propiedad

**Propiedad 5 - Estructura causal**:
- Algunos eventos causan otros; hay relaciones causa-efecto estables
- **Relevancia**: El experimento de Killeen demuestra que los organismos pueden percibir esta estructura directamente

**Propiedad 6 - Regularidades locales**:
- Patrones que se repiten en contextos similares  
- **Relevancia**: La conducta inducida aprovecha regularidades—respuestas apropiadas al tipo de reforzador tienden a ser exitosas

#### Relación con el Capítulo 3: Analogía Evolución-Aprendizaje

La analogía se fortalece y precisa:

**Nivel de variabilidad**:
- Evolución: Mutación y recombinación → variabilidad genética
- Aprendizaje: Conducta inducida → variabilidad conductual

**Nivel de selección**:
- Evolución: Selección natural → fenotipos con mayor éxito reproductivo
- Aprendizaje: Contingencia R→SBI → respuestas con mayor control causal

**Nivel de herencia**:
- Evolución: Genes → transmisión a descendientes
- Aprendizaje: Memoria → incremento de probabilidad de respuesta

**Limitación de la analogía**:
- En evolución, la variación es ciega (mutaciones son aleatorias)
- En aprendizaje, la variación está **sesgada** (conducta inducida es apropiada al contexto)
- Esto hace al aprendizaje más eficiente que la evolución para adaptación rápida

#### Relación con el Enfoque Houston & McNamara

Recordemos del Cap. 2 la distinción crucial:

**Nivel de optimización**: ¿Qué sería adaptativo?
- Pregunta: ¿Es adaptativo asignar crédito solo a respuestas que realmente controlan reforzadores?
- Respuesta: **Sí, absolutamente**. Asignar crédito a respuestas no-contingentes sería desperdiciar esfuerzo.

**Nivel de mecanismos**: ¿Qué mecanismo implementa esa solución?
- Pregunta: ¿Cómo computan los organismos P(SBI|R) vs. P(SBI|no-R)?
- Respuesta: Algún proceso de **comparación estadística** sensible a frecuencias relativas, **modulado por payoffs** (como muestra Killeen)

**Insight clave**: 
La evolución no seleccionó un mecanismo óptimo en cada instancia individual, sino un mecanismo **robusto y eficiente** a través de la distribución de entornos donde los ancestros evolucionaron.

Los experimentos de este capítulo muestran que el mecanismo es:
- **Sensible a correlaciones** (no solo contigüidad)  
- **Modulable por consecuencias** (sensible a payoffs)  
- **Ecológicamente racional** (usa conducta inducida apropiada al tipo de SBI)

---

## Parte VIII: Hacia los Modelos Formales

Los hallazgos de este capítulo establecen los **fenómenos empíricos** que los modelos formales del aprendizaje deben explicar. En los próximos capítulos veremos especificaciones matemáticas precisas.

### Preparación para el Capítulo 10: Correlación, Tiempo y Contingencia

En el próximo capítulo formalizaremos los conceptos que hemos introducido aquí:

- **Formalización de contingencia**: ΔP = P(SBI|R) - P(SBI|no-R)
- **Papel del tiempo**: Efectos de intervalo entre ensayos, duración de estímulos
- **Bloqueo y ensombrecimiento**: Competencia entre elementos por asignación de crédito
- **Validez predictiva vs. causal**: Refinamiento de cuándo algo "merece" crédito

### Preparación para el Capítulo 11: Modelo de Rescorla-Wagner

El modelo R-W proporcionará un algoritmo específico para cómo se actualizan las asociaciones ensayo a ensayo:

**Regla de aprendizaje**:
ΔV = α β (λ - ΣV)

Donde:
- V = fuerza asociativa (predicción)
- α = tasa de aprendizaje del estímulo/respuesta
- β = tasa de aprendizaje del reforzador  
- λ = magnitud del reforzador
- ΣV = suma de predicciones de todos los elementos presentes

Este modelo captura formalmente la idea de que el aprendizaje depende de **error de predicción**: λ - ΣV.

### Preparación para el Bloque IV: El Problema de la Acción

Saber *qué respuesta* controla un reforzador (asignación de crédito) es necesario pero no suficiente. También necesitamos saber:

**Capítulo 13 - Ley del Efecto y Programas de Refuerzo**:
- ¿Cómo afecta la **frecuencia** de reforzamiento a la tasa de respuesta?
- ¿Cómo afecta la **magnitud** del reforzador?
- ¿Qué papel juegan los **programas de refuerzo** (razón, intervalo)?

**Capítulo 14 - Acción como Elección**:
- Cuando hay **múltiples respuestas** disponibles, ¿cómo se distribuye el comportamiento?
- ¿Es esto una decisión racional?

**Capítulos 15-16 - Igualación y Maximización**:
- ¿Los organismos distribuyen su comportamiento de forma **óptima**?
- ¿Igualan tasas de respuesta a tasas de reforzamiento?
- ¿Maximizan obtención de reforzadores?

**La distinción crucial**:
- **Asignación de crédito**: Identifica *qué hacer* (este capítulo)
- **Problema de la acción**: Determina *cuánto hacerlo* (Bloque IV)

---

## Conclusiones

De los experimentos presentados en este capítulo alcanzamos las siguientes conclusiones:

### Sobre el Mecanismo General

1. La evolución ha seleccionado mecanismos de aprendizaje que buscan los mejores **predictores causales** de SBIs, no solo asociaciones temporales.

2. Existen **dos tipos de sesgos inductivos** complementarios:
   - **Tipo 1**: Reducen el espacio de respuestas candidatas (conducta inducida)
   - **Tipo 2**: Determinan prioridad de evaluación (contingencia)

3. Los sesgos incluyen **relevancia biológica**, **novedad**, **contigüidad**, pero ninguno es determinante por sí solo.

### Sobre la Contigüidad

4. La **contigüidad NO es necesaria**: Las ratas y palomas aprenden respuestas con demoras de 10-32 segundos entre respuesta y reforzador.

5. La **contigüidad NO es suficiente**: La mera presentación del reforzador independiente de la respuesta no genera aprendizaje de esa respuesta.

6. **Mientras más cercano** esté el reforzador de la respuesta, más fácil es la adquisición—pero la proximidad **facilita**, no **causa**, el aprendizaje.

7. Aún eliminando completamente la posibilidad de contigüidad accidental, los animales adquieren respuestas que generan reforzadores demorados.

### Sobre la Contingencia

8. Lo que determina el aprendizaje es la **contingencia estadística**: P(SBI|R) > P(SBI|no-R).

9. Los organismos son sensibles a esta relación probabilística, no solo a frecuencias absolutas de reforzamiento.

10. Existe **competencia** entre elementos por asignación de crédito (como veremos formalmente en Cap. 10).

### Sobre la Percepción de Causalidad

11. Los organismos pueden **discriminar** entre consecuencias dependientes e independientes de su respuesta.

12. Esta discriminación sigue los principios de **Teoría de Detección de Señales**:
    - Hay discriminabilidad (d' > 0)
    - Hay modulación por payoffs (criterio β es sensible a costos/beneficios)

13. El juicio de causalidad **varía en función** de la ganancia y el costo asociados—es una decisión racional bajo incertidumbre.

14. Existe una **ventana temporal de causalidad**: eventos dentro de ~0.2-1.0 segundos de la respuesta pueden ser tratados como causados por ella.

### Sobre la Conducta Inducida

15. La presentación de un SBI **induce** un conjunto tipificado de respuestas apropiadas al tipo de reforzador.

16. Estas respuestas se organizan **temporalmente**: respuestas interinas (búsqueda/exploración) temprano en el intervalo, respuestas terminales (aproximación/consumación) cerca del reforzador.

17. La conducta inducida **reduce el espacio de búsqueda** y proporciona las respuestas candidatas sobre las cuales operará la selección por contingencia.

### Integración

18. El aprendizaje instrumental requiere **dos mecanismos complementarios**: inducción de variabilidad + selección por contingencia.

19. Estos mecanismos son **análogos** a variación + selección en la evolución, pero con la ventaja de que la variación está **sesgada** (no ciega).

20. El sistema completo es **ecológicamente racional**: explota las propiedades estadísticas de los entornos naturales y toma decisiones sensibles a costos y beneficios.

---

## Ejercicios

### Ejercicios Conceptuales

**1. Predicción vs. Control**

Explica por qué aprender que un estímulo predice comida tiene diferente valor adaptativo que aprender que una respuesta produce comida. 

a) Da dos ejemplos concretos de situaciones naturales donde cada tipo de aprendizaje sería especialmente valioso.

b) ¿Hay situaciones donde sería adaptativo aprender la relación E→SBI pero *no* la relación R→SBI? ¿O viceversa?

**2. Contigüidad vs. Contingencia**

Un estudiante afirma: "No entiendo la diferencia. Si dos eventos siempre ocurren juntos (contingencia perfecta), entonces siempre están contiguos. Y si siempre están contiguos, entonces son contingentes. ¿No es lo mismo?"

a) ¿Cómo responderías? 

b) Proporciona un ejemplo concreto donde hay contigüidad sin contingencia.

c) Proporciona un ejemplo concreto donde hay contingencia sin contigüidad (estricta).

**3. Interpretando Superstición**

Reinterpreta el experimento de "superstición" de Skinner usando los conceptos de conducta inducida y contingencia.

a) ¿Por qué cada paloma desarrolla un patrón diferente?

b) ¿Por qué el patrón se estabiliza en lugar de cambiar continuamente?

c) ¿Dirías que las palomas tienen una "superstición" en el sentido cotidiano de la palabra? ¿Por qué sí o no?

**4. Ventana Causal**

En el experimento de Killeen, las palomas trataban eventos dentro de ~0.2-0.4 segundos como potencialmente causados por ellas.

a) ¿Por qué sería adaptativo tener una ventana temporal de causalidad? 

b) ¿Qué consecuencias tendría una ventana demasiado amplia (ej. 10 segundos)?

c) ¿Qué consecuencias tendría una ventana demasiado estrecha (ej. 0.01 segundos)?

d) ¿Esperarías que la ventana sea la misma para todas las especies? ¿Por qué?

**5. Dos Mecanismos**

Este capítulo argumenta que se necesitan dos mecanismos: (1) inducción de variabilidad, (2) selección por contingencia.

a) ¿Qué pasaría si solo existiera el Mecanismo 1 sin el Mecanismo 2?

b) ¿Qué pasaría si solo existiera el Mecanismo 2 sin el Mecanismo 1?

c) ¿Por qué necesitamos ambos?

### Ejercicios Cuantitativos

**6. Calculando Contingencia**

En un experimento, el tiempo se divide en intervalos de 1 segundo. Los datos son:

- En 1000 intervalos donde la rata presiona la palanca: 80 reforzadores
- En 1000 intervalos donde la rata NO presiona: 20 reforzadores

a) Calcula P(Ref|R) y P(Ref|no-R)

b) Calcula ΔP = P(Ref|R) - P(Ref|no-R)

c) ¿Existe contingencia positiva? ¿Esperarías aprendizaje?

d) Si P(Ref|no-R) aumentara a 0.08, ¿qué pasaría con la contingencia? ¿Con el aprendizaje?

**7. Demora y Aprendizaje**

Basándote en la Figura 9.4 del experimento de Dickinson:

a) Estima visualmente la tasa de respuesta (resp/min) para demoras de: 2s, 16s, 32s, 64s

b) Grafica estos puntos (demora en eje X, tasa en eje Y)

c) ¿La relación parece lineal, logarítmica, o exponencial?

d) Si ajustaras una función de la forma: Tasa = a × e^(-b × Demora), estima los parámetros a y b

**8. Análisis ROC**

En el experimento de Killeen, una paloma mostró estos datos (P(FA), P(Hit)) bajo diferentes payoffs:

- Payoff bajo (1.8s comida): (0.10, 0.60)
- Payoff medio (2.8s comida): (0.25, 0.75)  
- Payoff alto (3.8s comida): (0.45, 0.88)

a) Grafica estos puntos en un espacio ROC

b) Asumiendo distribuciones normales de igual varianza, estima d' para cada condición (usa tablas z o aproximación)

c) ¿La discriminabilidad (d') cambia entre condiciones? ¿Qué implica esto?

d) ¿Cómo cambia el criterio β entre condiciones? (Ayuda: β = Z(FA) / Z(Hit))

**9. Ventana Temporal**

En la Figura 9.8 de Killeen, para payoff = 2.3s:

- P(FA | intervalo 0.2s) ≈ 0.40
- P(FA | intervalo 0.4s) ≈ 0.20
- P(FA | intervalo 1.0s) ≈ 0.05

a) ¿Qué función podrías usar para modelar P(FA) como función del intervalo?

b) Si la relación es exponencial P(FA) = a × e^(-b × t), estima a y b

c) Usando tu modelo, predice P(FA) para intervalo = 0.6s

### Ejercicios Aplicados

**10. Diseñando un Experimento**

Diseña un experimento para evaluar si los niños pequeños (3-5 años) pueden discriminar eventos que ellos causan de eventos aleatorios en un juego de tablet.

a) Describe la tarea específica

b) ¿Cómo manipularías la probabilidad de que sus acciones tengan efecto?

c) ¿Qué medirías para evaluar discriminación de causalidad?

d) ¿Cómo evaluarías si los niños son sensibles a payoffs (como las palomas de Killeen)?

e) Predice resultados basándote en los hallazgos del capítulo

**11. Conducta Supersticiosa Humana**

Los atletas tienen rituales pre-competencia que parecen "supersticiosos" (cierto par de calcetines, rutina de calentamiento específica, etc.).

a) Usando conducta inducida y contingencia percibida, explica cómo podrían desarrollarse

b) ¿Por qué podrían persistir a pesar de evidencia contraria?

c) Propón una forma experimental de distinguir superstición basada en contigüidad accidental vs. genuina contingencia parcial

d) ¿En qué condiciones podría ser *adaptativo* mantener rituales aunque no haya contingencia real?

**12. Aplicación Clínica**

Un terapeuta ABA trabaja con un niño autista usando reforzamiento para enseñar habilidades sociales (ej. contacto visual).

Basándote en los hallazgos sobre demora y contingencia:

a) ¿Qué tan importante es entregar el reforzador inmediatamente después de la respuesta deseada? Justifica con evidencia del capítulo.

b) En la práctica, a veces hay demoras inevitables (ej. preparar el reforzador). ¿Qué sugiere la evidencia sobre cuánta demora es tolerable?

c) ¿Qué problemas podrían surgir si hay demoras variables e impredecibles?

d) ¿Cómo podría el terapeuta aprovechar "conducta inducida" para facilitar el aprendizaje?

**13. Diseño de Videojuegos**

Eres diseñador de videojuegos y quieres que los jugadores aprendan una mecánica compleja (ej. combo de ataques).

a) Basándote en conducta inducida, ¿qué tipo de feedback inmediato deberías proporcionar para inducir respuestas apropiadas?

b) Basándote en contingencia, ¿cómo asegurarías que los jugadores aprendan la relación causal entre sus acciones y el éxito?

c) ¿Qué papel juega la demora entre acción y feedback? ¿Cuánto puedes demorar el feedback sin impedir aprendizaje?

d) ¿Cómo usarías los principios de percepción de causalidad para hacer que el juego se sienta "responsivo"?

### Ejercicio Integrador

**14. Síntesis Multi-Capítulo**

Integra conceptos de los Capítulos 2, 3, 6, 8 y 9:

a) Relaciona las "7 propiedades estadísticas del entorno" (Cap. 2) con:
   - Conducta inducida
   - Sensibilidad a contingencia
   - Ventana temporal de causalidad

b) Compara el proceso de aprendizaje instrumental con la selección natural (Cap. 3):
   - ¿En qué se parecen?
   - ¿En qué difieren crucialmente?
   - ¿Por qué el aprendizaje es más eficiente para adaptación rápida?

c) Conecta el experimento de Killeen con Teoría de Detección de Señales (Cap. 6):
   - ¿Qué es la "señal" en este contexto?
   - ¿Qué determina d'?
   - ¿Cómo se modula β?

d) Compara asignación de crédito para estímulos (Cap. 8) vs. para respuestas (Cap. 9):
   - ¿Qué tienen en común?
   - ¿Qué es único de respuestas?
   - ¿Se rigen por los mismos principios fundamentales?

---

## Figuras Especificadas

**Figura 9.1**: Curva de aprendizaje típica de Thorndike
- Datos: Thorndike (1898), gatos en caja problema
- Eje X: Número de ensayo (1-30)
- Eje Y: Tiempo para escapar (segundos)
- Mostrar curva descendente con variabilidad

**Figura 9.2**: Fotografías del experimento de Skinner sobre "superstición"
- Reproducción de Skinner (1948)
- Mostrar 3-4 palomas diferentes con sus conductas estereotipadas distintas
- Caption explicando variabilidad entre sujetos

**Figura 9.3**: Conducta inducida organizada temporalmente
- Datos: Staddon & Simmelhag (1971)
- Eje X: Intervalo entre reforzadores (0-12 segundos)
- Eje Y: Probabilidad de ocurrencia
- Curvas para R1, R3, R4, R7, R8
- Distinguir visualmente respuestas terminales vs. interinas

**Figura 9.4**: Efecto de demora en aprendizaje instrumental
- Datos: Dickinson et al. (1991)
- Panel A: Demora vs. tasa (Master vs. Yoke)
- Panel B: Tres sub-paneles (16s, 32s, 64s demora) mostrando adquisición

**Figura 9.5**: Aprendizaje con demora garantizada
- Datos: Lattal & Gleeson (1990)
- Cinco palomas en paneles separados
- Eje X: Sesiones, Eje Y: Respuestas/min (log)
- Mostrar adquisición clara

**Figura 9.6**: Sensibilidad a contingencia
- Datos: Hammond (1980)
- Tres paneles: 0.05-0.01, 0.05-0.05, 0.05-0.0
- Mostrar aprendizaje solo con contingencia positiva

**Figura 9.7**: Curvas ROC - Discriminación de causalidad
- Datos: Killeen (1978)
- Cuatro palomas (S1-S4)
- Eje X: P(FA), Eje Y: P(Hit)
- Diagonal = azar, curvas por encima

**Figura 9.8**: Falsas alarmas vs. intervalo temporal
- Datos: Killeen (1978)
- Eje X: Intervalo (segundos)
- Eje Y: P(Falsa Alarma)
- Curvas para diferentes payoffs
- Mostrar disminución con intervalo, aumento con payoff

---

## Lecturas Recomendadas

### Artículos Clásicos Fundamentales

**Thorndike, E. L. (1898)**. Animal intelligence: An experimental study of the associative processes in animals. *Psychological Review Monograph Supplements*, 2(4), i-109.
- El trabajo original que introdujo la Ley del Efecto—históricamente esencial

**Skinner, B. F. (1948)**. 'Superstition' in the pigeon. *Journal of Experimental Psychology*, 38, 168-172.
- Artículo clásico sobre conducta "supersticiosa"—importante aunque interpretación es cuestionable

**Staddon, J. E. R., & Simmelhag, V. L. (1971)**. The "superstition" experiment: A reexamination of its implications for the principles of adaptive behavior. *Psychological Review*, 78, 3-43.
- Análisis detallado que introduce conducta inducida—lectura esencial

### Sobre Contingencia y Demora

**Dickinson, A., Watt, A., & Griffiths, W. J. H. (1992)**. Free-operant acquisition with delayed reinforcement. *Quarterly Journal of Experimental Psychology*, 45B, 241-258.
- Estudio definitivo sobre efectos de demora—diseño experimental impecable

**Hammond, L. J. (1980)**. The effect of contingency upon the appetitive conditioning of free-operant behavior. *Journal of the Experimental Analysis of Behavior*, 34, 297-304.
- Demostración clara de contingencia vs. contigüidad—muy bien diseñado

**Lattal, K. A., & Gleeson, S. (1990)**. Response acquisition with delayed reinforcement. *Journal of Experimental Psychology: Animal Behavior Processes*, 16, 27-39.
- Control elegante de contigüidad accidental—complementa a Dickinson

### Sobre Percepción de Causalidad

**Killeen, P. R. (1978)**. Superstition: A matter of bias, not detectability. *Science*, 199, 88-90.
- Experimento brillante sobre percepción de causalidad y TDS—altamente recomendado

**Killeen, P. R. (1981)**. Incentive theory. *Nebraska Symposium on Motivation*, 29, 169-216.
- Desarrollo teórico más amplio sobre motivación e incentivos

### Textos de Referencia

**Domjan, M. (2014)**. *The Principles of Learning and Behavior* (7th ed.). Cengage Learning.
- Capítulos 5-6: Excelente cobertura equilibrada de condicionamiento instrumental

**Pearce, J. M. (2008)**. *Animal Learning and Cognition* (3rd ed.). Psychology Press.
- Capítulos 3-4: Perspectiva británica contemporánea sobre aprendizaje instrumental

**Mackintosh, N. J. (1974)**. *The Psychology of Animal Learning*. Academic Press.
- Tratamiento clásico comprensivo—denso pero invaluable

### Para Profundizar

**Gallistel, C. R., & Gibbon, J. (2000)**. Time, rate, and conditioning. *Psychological Review*, 107, 289-344.
- Análisis profundo del papel del tiempo—perspectiva alternativa a asociacionismo

**Killeen, P. R., & Pellón, R. (2013)**. Adjunctive behaviors are operants. *Learning & Behavior*, 41, 1-24.
- Análisis moderno de conducta inducida—actualización de Staddon & Simmelhag

**Williams, B. A. (1989)**. Signal functions of the unconditioned stimulus. *Quarterly Journal of Experimental Psychology*, 41B, 241-256.
- Sobre cómo los reforzadores funcionan también como señales

---

## Notas Técnicas

### Nota 1: Discretización del Tiempo

Varios experimentos usan "discretización del tiempo"—dividir el continuo temporal en intervalos discretos (típicamente 1 segundo). Esto permite manipular independientemente P(ref|R) y P(ref|no-R).

**Ventajas**:
- Control experimental preciso de contingencia
- Puede calcular exactamente ΔP
- Elimina ambigüedades sobre "cuándo" ocurrió una respuesta

**Desventajas**:
- Artificial—el tiempo es continuo en ambientes naturales
- Puede no capturar dinámicas temporales finas
- Elección del intervalo es arbitraria (¿por qué 1s y no 0.5s o 2s?)

### Nota 2: Procedimiento Yokeado (Yoked Control)

Un sujeto "yokeado" recibe exactamente los mismos eventos que un sujeto experimental, pero en tiempos determinados por el comportamiento del sujeto experimental, no por su propio comportamiento.

**Lógica**:
- Controla por cantidad total de reforzadores
- Controla por distribución temporal de reforzadores
- Controla por contigüidades accidentales (en promedio)
- Aísla el efecto de contingencia (dependencia causal)

**Limitación**:
- Puede haber diferencias sutiles en microestructura temporal
- El yokeado experimenta "random" lo que el master experimenta "contingente"

### Nota 3: DRO (Differential Reinforcement of Other behavior)

En un procedimiento DRO estándar, el reforzador se entrega si el sujeto **no ejecuta** la respuesta target durante un período.

El DRO modificado de Lattal:
- Respuesta → inicia timer de 10s
- Si no hay más respuestas en 10s → reforzador
- Si hay respuesta antes de 10s → timer reinicia

Esto **garantiza** demora mínima de 10s entre cualquier respuesta y reforzador.

### Nota 4: Conducta Interina vs. Terminal

**Conducta Terminal**:
- Probabilidad aumenta hacia final del intervalo
- Típicamente apropiada para consumación del reforzador
- Ej: orientarse al comedero, lamer, picar pared del comedero

**Conducta Interina**:
- Probabilidad máxima en medio del intervalo  
- Típicamente exploratoria o de actividad general
- Ej: picar piso, girar, moverse

**Hipótesis funcional**: 
- Terminal = preparación para reforzador inminente
- Interina = ocupación del tiempo de espera

Esto será relevante cuando veamos teorías de control temporal en cursos avanzados.

### Nota 5: Relación con Condicionamiento Clásico

Aunque este capítulo se enfoca en condicionamiento instrumental (R→SBI), el organismo también experimenta condicionamiento clásico simultáneamente:

- Contextos predicen reforzador (contexto → SBI)
- Estímulos temporales predicen reforzador (tiempo → SBI)
- Consecuencias sensoriales de la respuesta predicen reforzador (feedback → SBI)

Esto crea **interacciones complejas** entre sistemas de aprendizaje que se exploran en ACA II y cursos avanzados.

